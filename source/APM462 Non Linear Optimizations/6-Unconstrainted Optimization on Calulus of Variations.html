<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>6-Unconstrainted Optimization on Calulus of Variations - Notes Portal</title>

<link rel="icon" type="image/gif" href="https://lihd1003.github.io/assets/images/logo.png">
<link rel="stylesheet" href="https://lihd1003.github.io/assets/css/vendor.css" />
<link rel="stylesheet" href="https://lihd1003.github.io/assets/css/style.css" />
<link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet">
<script src="https://kit.fontawesome.com/98fa07784c.js"></script>



<style type="text/css">
/* Overrides of notebook CSS for static HTML export */

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="https://lihd1003.github.io/UofT-Course-Material-Repo/index/custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
	<!-- header -->
   <header class="header-sticky header-dark">
    <div class="container">
      <nav class="navbar navbar-expand-lg navbar-dark">
        <a class="navbar-brand" href="./index.html">
          <img class="navbar-logo navbar-logo-light" src="https://lihd1003.github.io/assets/images/logo.png" alt="Logo">
          <img class="navbar-logo navbar-logo-dark" src="https://lihd1003.github.io/assets/images/logo.png" alt="Logo">
        </a>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav align-items-center mr-auto">
          </ul>

          <ul class="navbar-nav align-items-center mr-0">
            <li class="nav-item">
              <a href="https://github.com/lihd1003" class="nav-link waves-effect waves-light" target="_blank">
                <i class="icon-github mr-2"></i>GitHub
              </a>
            </li>
            <li class="nav-item">
              <a href="https://github.com/lihd1003/UofT-Course-Material-Repo" class="nav-link waves-effect waves-light" target="_blank">
                <i class="icon-star mr-2"></i>Star the Repo
              </a>
            </li>
          </ul>
        </div>
      </nav>
    </div>
  </header>

<section class="hero hero-with-header text-white" data-top-top="transform: translateY(0px);" data-top-bottom="transform: translateY(250px);">
    <div class="image image-overlay" style="background-image:url(https://lihd1003.github.io/assets/images/black.jpg)"></div>
    <div class="container">
      <div class="row align-items-center">
        <div class="col text-shadow">

          <h1 class="mb-0">6-Unconstrainted Optimization on Calulus of Variations</h1>
        </div>
      </div>
    </div>
 </section>
 <section class="bg-white sec" id="project">
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Introducing-The-Calculus-of-Variations">Introducing The Calculus of Variations<a class="anchor-link" href="#Introducing-The-Calculus-of-Variations">&#182;</a></h1><p>Consider the problem
\begin{align*}
\text{minimize } &amp;F[u] \\
&amp;u \in \mathcal{A},
\end{align*}
where $\mathcal{A}$ is a set of functions. Here, $F$ is a function of functions, often called a <strong>Functional</strong>. This is the general unconstrained calculus of variations problem.</p>
<p>For example, consider
$$\mathcal{A} = \{ u \in C^1([0, 1], \mathbb R) : u(0) = u(1) = 1  \}$$
Define $F : \mathcal{A} \to \mathbb R$ by
$$F[u(\cdot)] := \frac{1}{2} \int_0^1 (u(x)^2 + u'(x)^2) \, dx$$
To solve the minimization problem
\begin{align*}
\text{minimize } &amp;F[u] \\
&amp;u \in \mathcal{A}
\end{align*}
is to find a $u^* \in \mathcal{A}$ such that $F[u^*] \leq F[u]$ for all $u \in \mathcal{A}$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Thrm.-Fundamental-Lemma-of-Calculus-of-Variations"><em>Thrm</em>. Fundamental Lemma of Calculus of Variations<a class="anchor-link" href="#Thrm.-Fundamental-Lemma-of-Calculus-of-Variations">&#182;</a></h2><p><strong>Claim</strong>. Suppose $g \in C^0([a,b])$. If $\int_a^b g(x)v(x) \, dx = 0$ for all test functions $v$ on $[a,b]$, then $g \equiv 0$ on $[a,b]$.</p>
<p><em>proof</em>. Suppose $g\not\equiv 0$. Then there is an $x_0 \in (a,b)$ such that $g(x_0) \neq 0$. (We can ensure that $x_0$ is in the interior of the interval because of continuity.) Assume without loss of generality that $g(x_0) &gt; 0$. There exists an open neighbourhood $(c,d)$ of $x_0$ inside $(a,b)$ on which $g$ is positive. Let $v$ be a $C^1$ function on $[a,b]$ such that $v &gt; 0$ on $(c,d)$ and $v = 0$ otherwise. Then $v$ is a test function on $[a,b]$, so by the hypotheses,
$0 = \int_a^b g(x)v(x) \, dx = \int_c^d g(x)v(x) \, dx &gt; 0$
a contradiction.</p>
<p><strong>Intuitions</strong>. Fix $v \in C^1([0,1],\mathbb R)$ with $v(0) = v(1) = 0$. Suppose $u^*$ is a minimizer of $F$ on $\mathcal{A}$. Clearly $u^* + sv \in \mathcal{A}$ for all $s \in \mathbb R$. Define $f : \mathbb R \to \mathbb R$ by $f(s) := F[u^* + sv]$. Then $f(s) \geq f(0)$ for all $s$, since $u^*$ is a minimizer of $F$. Then $0$ is a minimizer of $f$, implying $f'(0) = 0$. How do we actually compute $f'(0)$? Since
\begin{align*}
f(s) &amp;= \frac{1}{2} \int_0^1 (u^*(x) + sv(x))^2 + (u^{*'}(x) + sv'(x))^2 \, dx \\
&amp;= \frac{1}{2} \int_0^1 (u^*(x)^2 + u^{*'}(x)^2) \, dx + s\int_0^1 ( u^*(x)v(x) + u^{*'}(x)v'(x) ) \, dx + \frac{s^2}{2} \int_0^1 (v(x)^2 + v'(x)^2) \, dx,
\end{align*}
implying that
$$
f'(s) = \int_0^1 ( u^*(x)v(x) + u^{*'}(x)v'(x) ) \, dx + s\int_0^1 (v(x)^2 + v'(x)^2) \, dx,
$$
or
$$
\tag{*}
0 = \int_0^1 ( u^*(x)v(x) + u^{*'}(x)v'(x) ) \, dx \text{ for all } v \in C^1([0,1], \mathbb R) \text{ such that } v(0)=v(1)=0.
$$
The above equality holds for all $v \in C^1([0,1], \mathbb R)$ such that $v(0)=v(1)=0$. This is a primitive form of the first order necessary conditions.</p>
<p>Let us call the functions $v$ described in (<em>) the test functions on $[0,1]$. We would like to write (</em>) in a more useful way. Let us make the simplifying assumption that $u^*$ is $C^2$. Integration by parts gives
$$
\int_0^1 u^{*'}(x)v'(x) \, dx = \underset{=0}{\left. u^{*'}(x)v(x) \right|_0^1} - \int_0^1 u^{*''}(x) v(x) \, dx = \int_0^1 u^{*''}(x) v(x) \, dx.
$$
By substituting this into (<em>) we obtain
$$
\int_0^1 (u^</em>(x)v(x) - u^{<em>''}(x)v(x))\, dx = 0.
$$
Factor the common $v$ out to get
$$
\int_0^1 (u^</em>(x) - u^{<em>''}(x))v(x) \, dx = 0 \text{ for all test functions } v \text{ on } [0,1].
$$
So we have a continuous function $u^</em>(x) - u^{<em>''}(x)$ that is zero whenever "integrated against test functions". We claim that any function satisfying this condition must be zero. This result or its variations is called the fundamental lemma of the calculus of variations. We shall show that $u^</em> = u^{*''}$ on $[0,1]$; this gives us the first order necessary conditions we wanted in the first place.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Defn.-Variational-Derivative"><em>Defn</em>. Variational Derivative<a class="anchor-link" href="#Defn.-Variational-Derivative">&#182;</a></h3><p>Given $u \in \mathcal{A}$, suppose there is a function $g : [a,b] \to \mathbb R$ such that 
$$\left. \frac{d}{ds} \right|_{s = 0} F[u + sv] = \int_a^b g(x) v(x) \, dx$$
for all test functions $v$ on $[a,b]$. Then $g$ is called the variational derivative of $F$ at $u$. We denote the function $g$ by $\frac{\delta F}{\delta u}(u)$.</p>
<p>We can think of $\frac{\delta F}{\delta u}(u)$ as an analogue of the gradient. We have
$$\left. \frac{d}{ds} \right|_{s = 0} F[u + sv] = \int_a^b \frac{\delta F}{\delta u}(u)(x) v(x) \, dx$$
for all test functions $v$ on $[a,b]$. Compare this with the finite-dimensional formula
$$\left. \frac{d}{ds} \right|_{s=0} f(u + sv) = \nabla f(u) \cdot v = \sum_{i=1}^n \nabla f(u)_i v_i$$
if one thinks of the integral as an "infinite sum of infinitesimally small pieces", then we can understand how the functional derivative might be an "infinite-dimensional" version of the gradient.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Euler-Lagrange-Equation-in-1-Dim">Euler Lagrange Equation in 1-Dim<a class="anchor-link" href="#Euler-Lagrange-Equation-in-1-Dim">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Lemma</strong> (A corollary of Fundamental Lemma) Suppose $u_* \in \mathcal{A}$ satisfies $u_* + v \in \mathcal{A}$ for all test functions $v$ on $[a,b]$. Then if $u_*$ minimizes $F$ on $\mathcal{A}$ and if $\frac{\delta F}{\delta u}(u_*)$ exists and is continuous, then $\frac{\delta F}{\delta u}(u_*) \equiv 0$.</p>
<h2 id="Thrm.-Euler-Lagrange-equation"><em>Thrm</em>. Euler-Lagrange equation<a class="anchor-link" href="#Thrm.-Euler-Lagrange-equation">&#182;</a></h2><p><strong>Claim</strong>. Suppose $L,u$ are $C^2$ functions. Then $\frac{\delta F}{\delta u}(u)$ exists, is continuous, and
$\frac{\delta F}{\delta u}(u)(x) = -\frac{d}{dx} L_p(x,u(x), u'(x)) + L_z(x,u(x),u'(x))$</p>
<p><em>proof</em>. Let $v$ be a test function on $[a,b]$. Then
\begin{align*}
\left. \frac{d}{ds} \right|_{s=0} F[u + sv] &amp;= \left. \frac{d}{ds} \right|_{s=0} \int_a^b L(x, u(x) + sv(x), u'(x) + sv'(x)) \, dx \\
&amp;=  \int_a^b \left. \frac{d}{ds} \right|_{s=0} L(x, u(x) + sv(x), u'(x) + sv'(x)) \, dx \\
&amp;= \int_a^b \left( L_x(\cdots) \frac{dx}{ds} + L_z(\cdots)\frac{d}{ds}(u(x) + sv(x)) + L_p(\cdots)\frac{d}{ds}(u'(x) + sv'(x)) \right) \, dx \\
&amp;= \int_a^b \left( L_z(x,u(x),u'(x))v(x) + L_p(x,u(x),u'(x))v'(x) \right)\, dx \\
&amp;= \int_a^b L_z(x,u(x),u'(x))v(x) \, dx + \int_a^b L_p(x,u(x),u'(x))v'(x) \, dx \\
&amp;= \int_a^b \left( -\frac{d}{dx} L_p(x,u(x),u'(x)) + L_z(x,u(x),u'(x)) \right) v(x) \, dx \qquad \text{integration by parts.}
\end{align*}
Since $u$ and $L$ are $C^2$, the function in the integrand is continuous. By the definition of the variational derivative we have the desired result.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Thrm.-DuBois-Raymond-Lemma"><em>Thrm</em>. DuBois-Raymond Lemma<a class="anchor-link" href="#Thrm.-DuBois-Raymond-Lemma">&#182;</a></h2><p>The lemma allows us to relax the restrictions for the Euler-Lagrange equation to hold from twice continuously differentiable to only once continuously differentiable.</p>
<p><strong>Claim</strong>. Suppose $\alpha, \beta$ are continuous functions on $[a,b]$ such that $\int_a^b ( \alpha(x)v(x) + \beta(x)v'(x) ) \, dx = 0$
for all test functions $v$ on $[a,b]$. Then $\beta$ is $C^1$, and $\beta' = \alpha$ on $[a,b]$.</p>
<p><em>proof</em>. Let $A(x) = \int_a^x \alpha(t) \, dt$ be an antiderivative of $\alpha$. Since $\alpha$ is continuous, $A$ is $C^1$. Then
$$
\int_a^b \alpha(x) v(x) \, dx = \int_a^b A'(x)v(x) \, dx = -\int_a^b A(x)v'(x) \, dx.
$$
By the original assumption,
$$
0 = \int_a^b (\alpha(x)v(x) + \beta(x)v'(x)) \, dx = \int_a^b(-A(x) + \beta(x))v'(x) \, dx.
$$
We are done if we are able to show that $-A(x) + \beta(x)$ is constant on $[a,b]$. Let $\gamma = -A + \beta$. Define $C$ to be the constant
$$
C := \frac{1}{b-a}\int_a^b \gamma(t) \, dt,
$$
so that $\int_a^b (\gamma(t) - C) \, dt = 0$. Define $v(x) := \int_a^x (\gamma(t) - C) \, dt$. The function $v$ is $C^1$ since $\gamma(t) - C$ is continuous, and $v(a) = v(b) = 0$; so $v$ is a test function on $[a,b]$. By some algebra,
$$
\int_a^b (\gamma(x) - C)^2 \, dx = \int_a^b (\gamma(x) - C)v'(x) \, dx = 0.
$$
Since $(\gamma(x) - C)^2 \geq 0$ on $[a,b]$, we must have $\gamma(x) = C$. Therefore $\gamma$ is constant, which proves the lemma.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example">&#182;</a></h3><p>Consider two points $(a,A), (b,B)$ in $\mathbb R^2$ with $a &lt; b$. We seek a function $u$ on $[a,b]$ with $u(a) = A$, $u(b) = B$, and with
$$
F[u] := \int_a^b \sqrt{1 + u'(x)^2} \, dx
$$
minimized. Denote by $\mathcal{A}$ the set of $C^1$ functions $u$ with $u(a) = A$ and $u(b) = B$. Suppose that $u_*$ is a minimizer. Then, by the previous lemma applied to the last result of the previous lecture, $u_*$ satisfies the Euler-Lagrange equation. Let $L(x,z,p) := \sqrt{1 + p^2}$. Then $L_z = 0$, and
$$
L_p = \frac{p}{\sqrt{1 + p^2}}.
$$
The Euler-Lagrange equation is, in this case,
$$
\tag{*}
0 = -\frac{d}{dx} L_p + L_z = -\frac{d}{dx} \frac{u_*'(x)}{\sqrt{1 + u_*'(x))^2}}.
$$
This implies that 
$$
u_*'(x) = C\sqrt{1 + u_*'(x)^2}
$$
for some constant $C$, implying
$$
u_*'(x)^2 = C(1 + u_*'(x)^2) = C + C u_*'(x)^2,
$$
giving
$$
u_*'(x)^2(1 - C) = C,
$$
hence $u_*'$ is constant, or $u_*(x) = \alpha x + \beta$ for some constants $\alpha, \beta$. As expected, the minimizer is a line. This answer is expected, since the shortest path joining two points is the line joining them.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example:-Area-of-Revolution">Example: Area of Revolution<a class="anchor-link" href="#Example:-Area-of-Revolution">&#182;</a></h3><p>Suppose $u$ is a $C^1$ function on an interval $[a,b]$. Consider the surface of revolution obtained by rotating the graph of $u$ on $[a,b]$ about the $x$-axis. Consider the functional
$$
F[u] := \text{area of the surface of revolution obtained by rotating $\Gamma_u$ about the $x$-axis},
$$
which is, by some calculus,
$$
F[u] = \int_a^b 2\pi u(x) \sqrt{1 + u'(x)^2} \, dx.
$$
With the set $\mathcal{A}$ of functions defined as in the previous example, we seek to find a function $u_* \in \mathcal{A}$ minimizing $F$ on $\mathcal{A}$.</p>
<p>In this example, the Lagrangian is $L(x,z,p) = 2\pi z \sqrt{1 + p^2}$, which gives
$$
L_z = 2\pi \sqrt{1 + p^2}
$$
and
$$
L_p = \frac{2\pi z p}{\sqrt{1 + p^2}}
$$
The Euler-Lagrange equation is, in this case,
$$
0 = -\frac{d}{dx} L_p + L_z = -\frac{d}{dx} \left[ \frac{2\pi u(x)u'(x)}{\sqrt{1 + u'(x)^2}} + 2\pi \sqrt{1 + u'(x)^2} \right].
$$
Cancel the $2\pi$'s to get the ODE
$$
\tag{**}
\left[ \frac{u(x)u'(x)}{\sqrt{1 + u'(x)^2}} + \sqrt{1 + u'(x)^2} \right] = 0.
$$
By magic, the general solution to this differential equation has the form
$$
u(x) = \beta \cosh\left(\frac{x - \alpha}{\beta} \right)
$$
for some constants $\alpha, \beta$. We won't argue why we got this solution, but we can differentiate it and check that it solves the ODE; uniqueness theorems give us what we want.
$$
u'(x) = \beta \sinh \left( \frac{x - \alpha}{\beta} \right) \frac{1}{\beta} = \sinh \left( \frac{x - \alpha}{\beta} \right),
$$
implying
$$
\sqrt{1 + u'(x)^2} = \cosh \left( \frac{x - \alpha}{\beta} \right).
$$
It is now obvious that $u$ solves (*<em>). Therefore a minimizer $u_</em>$ must be of the form
$$
u_*(x) = \beta \cosh \left( \frac{x - \alpha}{\beta} \right).
$$
We may use the boundary conditions to find $\alpha, \beta$.</p>
<p>Consider the special case $(a,A) = (0, 1)$ and $(b, B) = (1,0)$. The boundary conditions on $u_*$ give us the system
\begin{align*}
\beta \cosh \left( \frac{x - \alpha}{\beta} \right) &amp;= 1 \\
\beta \cosh\left( \frac{1 - \alpha}{\beta} \right) &amp;= 0.
\end{align*}
Since $\cosh$ is strictly positive, the second equation gives us $\beta = 0$, a contradiction. We conclude that there is no $C^1$ minimizer in this special case.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Euler-Lagrange-Equation-in-N-Dim">Euler-Lagrange Equation in N-Dim<a class="anchor-link" href="#Euler-Lagrange-Equation-in-N-Dim">&#182;</a></h1><p>We consider a functional
$$F[u] := \int_a^b L(x, u(x), u'(x)) \, dx$$
where $u : [a,.b] \to \mathbb R^n$. In this case,
$$L : [a, b] \times \mathbb R^n \times \mathbb R^n \to \mathbb R$$
Our general space of functions will be denoted by 
$$\mathcal{A} := \{ u : [a,b] \to \mathbb R^n : u \in C^1, u(a) = A, u(b) = B \}.$$
The Euler-Lagrange equation from the real-valued case generalizes to 
\begin{align*}
-\frac{d}{dx} \nabla_p L(x, u_*(x), u_*'(x)) + \nabla_z L(x, u_*(x), u_*'(x)) = 0.
\end{align*}
The proof is a straightforward generalization of the proof given when $n = 1$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example:-Newton's-Second-Law">Example: Newton's Second Law<a class="anchor-link" href="#Example:-Newton's-Second-Law">&#182;</a></h3><p>Let us consider an example from classical mechanics. We consider the physical situation of a point mass moving in a potential field. Denote by $V(x)$ the potential energy at a point $x$. The kinetic energy of a point of mass $m$ with velocity $v$ is $\frac{1}{2} m |v|^2$. Define the Lagrangian
$$L(t,x,v) = \frac{1}{2} m |v|^2 - V(x)$$
as the difference between the kinetic and potential energies. Suppose our particle is moving along a path $x = x(t)$ parametrized by time in $\R^n$. Our functional is
$$F[x] := \int_{t_1}^{t_2} \left( \frac{1}{2} m |\dot{x}(t)|^2 - V(x(t)) \right) \, dt$$
This represents the difference between the kinetic energy and the potential energy \emph{along the entire path}. We can think of it as the net change in energy from the kinetic energy to potential energy along the path.</p>
<p>In this case, the Euler-Lagrange equations for a a minimizing path $x(t)$ are
$$0 = -\frac{d}{dt} \nabla_v L(t, x(t), \dot{x}(t)) + \nabla_x L(t, x(t), \dot{x}(t))$$
One computes that 
\begin{align*}
\nabla_v L(t,x,v) &amp;= mv \\
\nabla_x L(t,x,v) &amp;= -\nabla V(x).
\end{align*}
Then the Euler-Lagrange equations are
$${m \ddot{x}(t) = -\nabla V(x).}$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Additional-Examples">Additional Examples<a class="anchor-link" href="#Additional-Examples">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example-1">Example 1<a class="anchor-link" href="#Example-1">&#182;</a></h2><p>_Consider $Q+scc^T$ where $Q$ is positive definite symmetric, prove that the largest eigenvalue $\mu_n(s)$ of $Q+scc^T$ is bounded by $a_2 + \beta s \leq \mu_n(s) \leq a_1 + \beta s$_</p>
<p><em>proof</em>. 
\begin{align*}
\mu_n(s) &amp;= \max_{\|x\|=1}\big\{x^T(Q+scc^T)x\big\}\\
&amp;= \max_{\|x\|=1} \big\{x^TQx + x^Tscc^Tx\big\}
\end{align*}
Because $Q$ is positive definite, $x^TQx \geq 0$, 
\begin{align*}
\mu_n(s) &amp;\geq \max_{\|x\|=1} \big\{x^Tscc^Tx\big\}\\
&amp;= \max_{\|x\|=1} \big\{x^Tcc^Tx\big\}s &amp;s\text{ is a scalar}
\end{align*}
Also, we have 
\begin{align*}
\mu_n(s) &amp;\leq \max_{\|x\|=1}\big\{x^TQx\big\} + \max_{\|x\|=1} \big\{x^Tscc^Tx\big\}\\
&amp;= \max_{\|x\|=1}\big\{x^TQx\big\} + \max_{\|x\|=1} \big\{x^Tcc^Tx\big\}s
\end{align*}
Let $\alpha_2 = 0, \alpha_1 = \max_{\|x\|=1}\big\{x^TQx\big\}, \beta = \max_{\|x\|=1} \big\{x^Tcc^Tx\big\}$, since $c\neq 0, \beta &gt; 0$. Therefore, 
$$a_2 + \beta s \leq \mu_n(s) \leq a_1 + \beta s$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example-2">Example 2<a class="anchor-link" href="#Example-2">&#182;</a></h2><p><em>Derive the formula $p(t):\mathbb R\rightarrow \mathbb R^2 := (x(t), y(t))$ where $p(t)$ is the position of point on the rim of a circle of radius $R$, the circle is rolling along the $x$-axis at a constant speed $a$. Assume $c(t) = (at, R)$ is the position of the center of the circle at $t$ and $p(0) = (0, 0)$.</em></p>
<p>Let $f(\theta):\mathbb R\rightarrow \mathbb R^2 := (R\cos\theta, R\sin\theta)$ be the parametric equation of the circle.</p>
<p>Consider the point $q(t) = (at, 0)$ on the rim of the circle at time $t$, let 
$$q_c(t) = q(t) - c(t) = (at, 0) - (at, R) = (0, -R)$$ be its position relative to the center of the circle, note that 
$$q_c(t) = f(-\pi/2) = (\cos(-\frac{\pi}{2}), \sin(-\frac{\pi}{2}))$$
Then, let $L$ be the arc of the circle between $q_c$ and $p_c$ and $\theta(t)$ be the angle subtended by arc $L$ from the center of the circle. Since the arc length is $at$, we have
\begin{align*}
\theta(0) - \theta(t) &amp;= \frac{at}{R}\\
\theta(t) &amp;= \theta(0) - \frac{at}{R}\\
\theta(t) &amp;= -\frac{\pi}{2} - \frac{at}{R}
\end{align*}
Therefore, let $q_c(t)$ be $p$'s position relative to the center of the circle, $$q_c(t) = f(\theta(t)) = \big(R\cos(-\frac{\pi}{2} - \frac{at}{R}), R\sin(-\frac{\pi}{2} - \frac{at}{R})\big)$$
so that 
$$p(t) = p_c(t) + c(t) = \big(at + R\cos(-\frac{\pi}{2} - \frac{at}{R}), R\sin(-\frac{\pi}{2} - \frac{at}{R})\big)$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example-3">Example 3<a class="anchor-link" href="#Example-3">&#182;</a></h2>$$F[\mu[\cdot] = \int_a^b L(x, \mu(x), \mu'(x))dx, x(a)=A, x(b)=B$$<p>_$L, \mu \in C^2$, partition $[a,b]$ into $x_0, ..., x_{n+1}$ where $x_i = a + \frac{b-a}{n+1}i$ so that we can approximate the functional by_ 
$$F:\mathbb R^n\rightarrow \mathbb R, F(\mu_1, ..., \mu_n) :=\sum_{i=1}^{n+1}L(x_i, \mu_i, \frac{\mu_i - \mu_{i-1}}{h})h$$</p>
<p>_(a) Calculate $\frac{dF}{d\mu_i}(\mu)$_
\begin{align*}
\frac{dF}{d\mu_i}(\mu) &amp;= \sum_{j=1}^{n+1}\frac{d}{d\mu_i}L(x_j, \mu_j, \frac{\mu_j - \mu_{j-1}}{h})h\\
&amp;= \frac{d}{d\mu_i}L(x_{i}, \mu_{i}, \frac{\mu_i - \mu_{i-1}}{h})h + \frac{d}{d\mu_i}L(x_{i+1}, \mu_{i+1}, \frac{\mu_{i+1} - \mu_{i}}{h})h\\
&amp;= L_z(x_{i}, \mu_{i}, \frac{\mu_i - \mu_{i-1}}{h})h\frac{d}{d\mu_i}\mu_i + L_p(x_{i}, \mu_{i}, \frac{\mu_i - \mu_{i-1}}{h})h\frac{d}{d\mu_i}\frac{\mu_i - \mu_{i-1}}{h}\\
&amp;\quad+L_p(x_{i+1}, \mu_{i+1}, \frac{\mu_{i+1} - \mu_{i}}{h})h\frac{d}{d\mu_i}\frac{\mu_{i+1} - \mu_{i}}{h}\\
&amp;= hL_z(x_{i}, \mu_{i}, \frac{\mu_i - \mu_{i-1}}{h}) - (L_p(x_{i+1}, \mu_{i+1}, \frac{\mu_{i+1} - \mu_{i}}{h})- L_p(x_{i}, \mu_{i}, \frac{\mu_i - \mu_{i-1}}{h}))
\end{align*}</p>
<p>_(b) Take $h\rightarrow 0$, show that $\frac{dF}{d\mu_i}(\mu) = 0\Rightarrow L_z(x, \mu(x), \mu'(x) - \frac{d}{dx}L_p(x, \mu(x), \mu'(x))) = 0$_</p>
<p><em>proof</em>. Since $\frac{dF}{d\mu_i}(\mu) = 0$
\begin{align*}
\lim_{h\rightarrow 0} \frac{1}{h}\frac{dF}{d\mu_i}(\mu) &amp;= \lim_{h\rightarrow 0}L_z(x_i, \mu_i, \frac{\mu_i-\mu_{i-1}}h) \\
&amp;\quad- \lim_{h\rightarrow 0}\frac{L_p(x_{i+1}, \mu_{i+1}, \frac{\mu_{i+1} - \mu_{i}}{h})- L_p(x_{i}, \mu_{i}, \frac{\mu_i - \mu_{i-1}}{h})}{h}\\
&amp;= L_z(x_i, \mu(x_i), \mu(x_i)')\\
&amp;\quad - \lim_{h\rightarrow 0}\frac{L_p(x_i+h, \mu(x_i+h), \mu'(x_i+h))- L_p(x_{i}, \mu(x_i), \mu'(x_i))}{h}\\
&amp;\text{by definition of derivative}\\
&amp;= L_z(x_i, \mu(x_i), \mu(x_i)') - \frac{d}{dx}L_p(x_i, \mu(x_i), \mu(x_i)')
\end{align*}
Therefore, for some $x\in[a,b]$, since $h\rightarrow 0$, we can partition $[a,b]$ s.t. $x\in \text{partition}(a, b)$, so that we have 
$$L_z(x_i, \mu(x_i), \mu(x_i)') - \frac{d}{dx}L_p(x_i, \mu(x_i), \mu(x_i)') = \lim_{h\rightarrow 0} \frac{1}{h}\frac{dF}{d\mu_i}(\mu) = 0$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example-4">Example 4<a class="anchor-link" href="#Example-4">&#182;</a></h2><p><em>Find FONC of</em>
\begin{align*}
\text{minimize}\quad &amp;F[\mu(\cdot)] := \int_a^b L(x, u(x), u'(x))dx\\
\text{subject to}\quad &amp;\mu\in \mathcal A:= \{\mu:[a,b]\rightarrow\mathbb R\mid \mu\in C^2, \mu(a) = A\}
\end{align*}</p>
<p>Let $\mu_*$ be the minimizer of the problem.<br>
Let $\mathcal T:= \{v:[a, b]\rightarrow\mathbb R\mid v\in C^2, v(a) = 0\}$ be the set of test functions so that $\forall v\in \mathcal T. \forall s\in\mathbb R. u_*+sv \in \mathcal A$.<br>
Then as what have been done in the class till the integrations by parts 
\begin{align*}
\frac{d}{ds}F[u_*+sv]
&amp;=\int_a^b \big[L_z(...) - \frac{d}{dx}L_p(...)\big]v(x)dx + \big[L_p(...)\mid_a^b\big]
\end{align*}
Since $v(a) = 0$, note that 
\begin{align*}
\big[L_p(x, u_*(x), u_*'(x))v(x)\mid_a^b\big] &amp;= L_p(b, u_*(b), u_*'(b))v(b) - L_p(a, u_*(a), u_*'(a))v(a)\\
&amp;= L_p(b, u_*(b), u_*'(b))v(b)
\end{align*}
Consider $v_1\in\mathcal T$ s.t. $v(b) = 0$, hence<br>
$$\big[L_p(x, u_*(x), u_*'(x))v(x)\mid_a^b\big] = 0$$ 
Given $u_*$ is the minimizer,<br>
$$0 = \frac{d}{ds}F[u_*+sv] =\int_a^b \big[L_z(...) - \frac{d}{dx}L_p(...)\big]v(x)dx$$
follows the original Euler-Lagrange equation, i.e. 
$$L_z(x, u_*(x), u_*'(x)) - \frac{d}{dx}L_p(x, u_*(x), u_*'(x)) = 0$$
Consider $v_2\in\mathcal T, v_2(b)\neq 0$, since we have to fulfill the necessary conditions for cases like $v_1$, we have 
$$L_z(x, u(x), u'(x)) - \frac{d}{dx}L_p(x, u(x), u'(x)) = 0$$
so that 
$$0 = \frac{d}{ds}F[u_*+sv] = 0 + L_p(b, u(b), u'(b))v(b)$$
Therefore, there are two FONC as
$$L_z(x, u_*(x), u_*'(x)) - \frac{d}{dx}L_p(x, u_*(x), u_*'(x)) = 0$$
$$L_p(b, u(b), u'(b))v(b) = 0$$</p>

</div>
</div>
</div>
    </div>
  </div>
</section>
  <script src="https://lihd1003.github.io/assets/js/vendor.js"></script>
  <script src="https://lihd1003.github.io/assets/js/app.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script>
    $("table").addClass("table table-lined")
  </script>
</body>

 


</html>
