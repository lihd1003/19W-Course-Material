{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "A sample from a distribution $p(x)$ is a single realization $x$ whose probability distribution is $p(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ancestral Sampling\n",
    "Given a DAG and the ability to sample from each of its factors given parents, we can then sample from the join distribution over all the nodes by ancestral sampling, i.e. start with some root, at each step, sample from any conditional distribution that haven't visited yet, whose parents have all been sampled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Monte Carlo\n",
    "Given $\\{x^{(r)}\\}^R \\sim p(x)$, then we can define $\\hat E = R^{-1}\\sum^R f(x^{(r)}) \\approx E_{x\\sim p}[f(x)]$. \n",
    "\n",
    "$\\hat E$ is an unbiased estimator as \n",
    "\\begin{align*}\n",
    "\\hat E &= E[R^{-1} \\sum^R f(x^{(r)})]\\\\\n",
    "&= R^{-1}\\sum^R E[f(x^{(r)})]\\\\\n",
    "&= R^{-1}\\sum^R E[f(x)]\\\\\n",
    "&= E\n",
    "\\end{align*}\n",
    "\n",
    "and the variance decreases as $R$ increases\n",
    "\\begin{align*}\n",
    "var(\\hat E) &= var\\bigg[R^{-1}\\sum^R f(x^{(r)})\\bigg]\\\\\n",
    "&= R^{-2}var\\bigg[\\sum^R f(x^{(r)})\\bigg]\\\\\n",
    "&= R^{-2}\\sum^R var[f(x^{(r)})] &\\text{samples are indep.}\\\\\n",
    "&= R^{-1}var(f(x))\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance Sampling\n",
    "Assume we are to estimate some $p$ from some $\\tilde p$ s.t. $p(x) = \\tilde p(x)/ Z$ and we further assume some simpler density $q$ form which it is easy to sample from and easy to evaluate $\\tilde q$ s.t. $q(x) = \\tilde q(x) / Z_q$\n",
    "\n",
    "Then, generate $R$ samples from $q$, i.e. \n",
    "$$\\{x^{(r)}\\}^R$ \\sim q(x)$$\n",
    "If these points are samples from $p(x)$ then we could estimate $\\Phi$ by \n",
    "$$\\Phi = E_{x\\sim p}(\\phi(x)) \\approx R^{-1}\\sum^R \\phi(x^{(r)}) = \\hat\\Phi$$\n",
    "\n",
    "#### Weights\n",
    "Note that the samples are generated from $q$, instead of $p$ so that we need some weights $w$ to trade off this difference, i.e. \n",
    "$$\\tilde w_r = \\frac{\\tilde p(x^{(r)})}{\\tilde q(x^{(r)})}$$\n",
    "so that \n",
    "\\begin{align*}\n",
    "\\Phi &= \\int \\phi(x)p(x)dx\\\\\n",
    "&= \\int \\phi(x)\\frac{p(x)}{q(x)}q(x)dx \\\\\n",
    "&\\approx R^{-1}\\sum^R \\phi(x^{(r)})\\frac{p(x^{(r)})}{q(x^{(r)})}\\\\\n",
    "&= \\frac{Z_q}{Z_p} \\frac{1}{R}\\sum_{r=1}^R \\phi(x^{(r)}) \\cdot \\frac{\\tilde p(x^{(r)})}{\\tilde q(x^{(r)})} \\\\ &= \\frac{Z_q}{Z_p} \\frac{1}{R}\\sum_{r=1}^R \\phi(x^{(r)}) \\cdot \\tilde w_r \\\\ &= \\frac{\\frac{1}{R}\\sum_{r=1}^R \\phi(x^{(r)}) \\cdot \\tilde w_r}{\\frac{1}{R}\\sum_{r=1}^R \\tilde w_r} \\\\ &= \\frac{1}{R}\\sum_{r=1}^R \\phi(x^{(r)}) \\cdot w_r \\\\ &= \\hat \\Phi_{iw}\n",
    "\\end{align*}\n",
    "\n",
    "However, take note that $\\hat\\Phi_{iw}$ is a biased estimator, although consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling \n",
    "Similar to importance sampling, but in this case we find some easier $q$ s.t. $$\\forall x. c\\tilde q(x) > \\tilde p(x)$$\n",
    "Then, the algorithm goes like\n",
    "\n",
    "for each iteration\n",
    "1. generate $x \\sim q(x)$\n",
    "2. generate $u \\sim Unif[0, c\\tilde q(x)]$\n",
    "3. evaluate $\\tilde p(x)$\n",
    "  - if $u > \\tilde p(x)$, reject\n",
    "  - else accept $x$ by append it to $\\{x^{(r)}\\}$\n",
    "\n",
    "#### Problem\n",
    "In high dimensions, such $c\\tilde q$ will be harder to find, hence $c$ must be huge and the acceptance rate will then be exponentially small in proportional to number of dimensions\n",
    "\n",
    "### Metropolis-Hastings Method\n",
    "Instead of using one $q$, let $q$ be some function depends on the current state of $x^{(t)}$, for example, $N(x^{(t)}, \\Sigma)$\n",
    "\n",
    "Then, for each iteration, \n",
    " - generate $x' \\sim q(x'|x^{(t)})$\n",
    " - compute $a = \\frac{\\tilde p(x')q(x^{(t)}|x')}{\\tilde p(x^{(t)})q(x'|x^{(t)})}$\n",
    " - if $a\\geq 1$ then accepted, otherwise accept with probability $a$. \n",
    " - Update $x^{(t+1)} =\\begin{cases} x' &\\text{if accept}\\\\x^{(t)} & \\text{if refuse}\\end{cases}$\n",
    " \n",
    " ### Problem with MH method\n",
    " - we are generating from a dependent sequences, and we cannot really estimate the variance. \n",
    " - Unable to know when it \"converge\", i.e. obtain enough samples that are effectively independent samples from $p$. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
