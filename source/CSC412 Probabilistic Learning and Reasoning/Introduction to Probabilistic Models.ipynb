{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Probabilistic Models\n",
    "\n",
    "Let r.v. $\\mathcal X = (X_1, ..., X_M)$ with the model relationships $p_\\theta(\\mathcal X)$. \n",
    "\n",
    "Assuming a generative distribution, i.e. $(X_1,...,X_M) \\sim p_{data}(\\mathcal X)$\n",
    "\n",
    "Then, the learning goal is to find best $p_{\\theta^*} \\approx p_{data}$. \n",
    "Therefore, the problem is to define \"best\" and methods to find the \"best\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Probabilistic Perspective on ML Tasks\n",
    "\n",
    "### Supervised\n",
    "Assuming the input data $X$, labels $C$, and continuous output $y$. \n",
    "\n",
    "Given $\\mathcal D = \\{(x,c)_1,...,(x,c)_M\\}$, assume $(x,c)\\sim p_{data}(X,C)$  \n",
    "__classification__ Let $c$ be discrete $$p(C\\mid X) = \\frac{p(X,C)}{p(X)} = \\frac{p(X,C)}{\\sum_{c\\in C} p(X,c)}$$\n",
    "\n",
    "\n",
    "__regression__ Let $y$ be continuous \n",
    "$$p(Y\\mid X) = \\frac{p(X,Y)}{p(X)} = \\frac{p(X,Y)}{\\int_Y p(X,y)dy}$$\n",
    "\n",
    "### Unsupervised\n",
    "$\\mathcal D = \\{(x)_1,...,(x)_M\\}$, assuming there exists some features (e.g. clustering) i.e. assuming $X, \\_ \\sim p(X,C_{hidden})$  \n",
    "Then, we still want to transfer the question into $p_\\theta (C\\mid X)$\n",
    "\n",
    "### Semi-supervised\n",
    "When labels are partially observed, for example, matrix completion problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Variables\n",
    "Never observed, encode modeling assumptions, infer complex features\n",
    "\n",
    "### Operations on the probabilistic models\n",
    "Generating data $x\\sim p_\\theta(x)$  \n",
    "Estimating likelihood  \n",
    "Inferencing  \n",
    "Learning the parameters\n",
    "\n",
    "### Considerations on Prob. Models\n",
    "efficient computations  \n",
    "compact representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality of Joint Distribution\n",
    "Suppose we have variables $T=\\{t_0,t_1\\},W=\\{w_0, w_1\\},M = \\{m_0, m_1\\}$, then the joint distribution $p(T,W,M)$ is parameterized with $2\\times 2 \\times 2= 8$ parameters. Hence if we add more states onto each variables, say we have $k$ states for each of $n$ variables. Then, the join distribution will have $k^n$ parameters. \n",
    "\n",
    "#### Reduce Dimensionality of Join Distribution\n",
    "With assumptions on the independence of variables, then we can reduce the dimensionality and reduce the number of parameters. \n",
    "\n",
    "note that __fully factorized__ means that \n",
    "$$p(T,W,M) = p(T)p(W\\mid T)p(M\\mid T,W) = p(M)p(T\\mid M)p(W\\mid T,M) =...$$\n",
    "\n",
    "suppose we have the assumption that $T,W$ are independent, then the factorization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Function\n",
    "$$l(\\theta; x) = \\log p(x\\mid \\theta)$$\n",
    "For iid. $x$, \n",
    "$$l(\\theta, x) = \\log(\\prod p(x^{(m)})\\mid \\theta) = \\sum \\log p(x^{(m)}\\mid \\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sufficient Statistics\n",
    "A __statistic__ is a deterministic function of a set of r.v. \n",
    "\n",
    "A __sufficient statistic__ is a statistic that conveys exactly the same information about the generative distribution as the entire dataset itself. i.e., inferences made from sufficient statistic, $T(x)$, are the same as those obtained from the entire data. $T(X)$ is a sufficient statistic for $X$ if \n",
    "$$T(x^{(1)}) = T(x^{(2)})=L(\\theta; x^{(1)}) = L(\\theta; x^{(2)}), \\forall \\theta$$\n",
    "a.k.a.\n",
    "$$P(\\theta| T(X)) = P(\\theta|X)$$\n",
    "By Neyman factorization theorem\n",
    "$$p(\\theta|T(X)) = f_\\theta(X) = h(x, T(x))g(T(x), \\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Sufficient Statistics for Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a data set on $N$ observations $X \\in \\{0, 1\\}^N $, then likelihood is \n",
    "\\begin{align*}\n",
    "l(\\theta; D) &= \\log p(D|\\theta) \\\\\n",
    "&= \\log \\sum_{i=1}^N \\theta^{x_i}(1-\\theta)^{1-x_i}\\\\\n",
    "&= \\sum^N x_i \\log\\theta + (1-x_i)\\log(1-\\theta)\\\\\n",
    "&= \\log\\theta\\sum^N x_i + \\log(1-\\theta)\\sum^N (1-x_i)\\\\\n",
    "&= \\log\\theta N_H + \\log(1-\\theta)N_T\\\\\n",
    "\\end{align*}\n",
    "so that $T(X) = N_H$ so that $h(x, T(x)) = 1, g(T(x), \\theta) = \\log\\theta N_H + \\log(1-\\theta)(N-N_T)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Sufficient Statistic for Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a data set $D \\in \\{1,2,..., K\\}^N$ and the model is $p(x_n = i\\mid \\theta) = \\theta_i$ w.r.t $\\sum^K \\theta_i = 1$\n",
    "\\begin{align*}\n",
    "l(\\theta; D) &= \\log \\prod_n \\theta_1^{x_n = 1}...\\theta_K^{x_n=K}\\\\\n",
    "&= \\sum_n\\sum_i \\mathbb I(x_n = i)\\log\\theta_i\\\\\n",
    "&= \\sum_i \\log\\theta_i \\sum_n \\mathbb I(x_n = i)\\\\\n",
    "&= \\sum_i \\log\\theta_i N_i\n",
    "\\end{align*}\n",
    "So that $N_i$'s are sufficient statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sufficient Statistics for general Exponential Family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, exponential family members have simple sufficient statistics for the natural statistics $\\eta$\n",
    "$$p(x|\\eta) = h(x)\\exp\\{\\eta^T T(x) - A(\\eta)\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sufficient Statistics for Univariate Normal\n",
    "\\begin{align*}\n",
    "p(x|\\theta) &= \\sqrt{2\\pi\\sigma^2}^{-1}\\exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})\\\\\n",
    "&= \\sqrt{2\\pi\\sigma^2}^{-1}\\exp(-\\frac{x^2}{2\\sigma^2} + \\frac{\\mu x}{\\sigma^2} - \\frac{u^2}{\\sigma^2})\\\\\n",
    "&= \\sqrt{2\\pi\\sigma^2}^{-1}\\exp(-\\frac{x^2}{2\\sigma^2} + \\frac{\\mu x}{\\sigma^2})\\exp( -\\frac{u^2}{4\\sigma^2})\n",
    "\\end{align*}\n",
    "So that $T(x) = \\begin{bmatrix}x^2\\\\x\\end{bmatrix}, \\eta = \\begin{bmatrix}-1/2\\sigma^2& \\frac{u}{\\sigma^2}\\end{bmatrix}$  \n",
    "$h(x, T(x)) = \\sqrt{2\\pi}^{-1}, g(T(x), \\eta) = \\sigma^{-1}\\exp(\\eta^TT(x))\\exp(\\frac{\\eta_1^2}{4\\eta_2})$"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
