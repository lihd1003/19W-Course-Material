---
title: Midterm Review
order: 25
---
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>Weak stationarity</h1>
<ul>
<li>Constant finite mean</li>
<li>Constant finite variance</li>
<li>the covariance is only a function of lag (time difference) instead of time dependent</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>Classical decomposition</h1>
<ul>
<li>Trend</li>
<li>Seasonal variation</li>
<li>Cyclic variation</li>
<li>irregular components</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>Steps of modeling</h1>
<ul>
<li>Plot and check for trend, seasonal, cyclic, and irregular components</li>
<li>Remove trend and seasonal component to get residuals</li>
<li>Choose to model to fit residuals</li>
<li>Forecasting carried out by forecasting residuals and then inverting the transformations carried out in step 2. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>Covariances</h1>
$$x_t = \frac{a_t}{3} + \frac{a_{t-1}}{3}, a_t \sim NID(0, \sigma^2)$$$$y_t = \frac{x_t}{2} - \frac{x_{t-2}}{2}$$<p></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
\begin{align*}
\gamma_x(0)
&amp;=cov(x_t, x_t)\\ 
&amp;=\frac{1}{9}cov(a_t + a_{t-1}, a_t + a_{t-1})\\  
&amp;=\frac{1}{9}( E(a_t a_t) + 2E(a_ta_{t-1}) + E(a_{t-1}a_{t-1}))\\  
&amp;=\frac{1}{9}(\sigma^2 + \sigma^2) = \frac{2\sigma^2}{9}\\
\gamma_x(1)
&amp;=cov(x_t, x_{t-1})\\
&amp;=\frac{1}{9}cov(a_t + a_{t-1}, a_{t-1} + a_{t-2})\\
&amp;=\frac{1}{9}( E(a_t a_{t-1}) + E(a_ta_{t-2}) + E(a_{t-1}a_{t-1}) + E(a_{t-1}a_{t-2}))\\ 
&amp;=\frac{\sigma^2}{9}\\
\gamma_x(h)
&amp;=cov(x_t, x_{t-h})\\ 
&amp;=\frac{1}{9}cov(a_t + a_{t-1}, a_{t-h-1} + a_{t-h-2})\\
&amp;=\frac{1}{9}( E(a_t a_{t-h-1}) + E(a_ta_{t-h-2}) + E(a_{t-1}a_{t-h-1}) + E(a_{t-1}a_{t-h-2}))\\
&amp;=0, \forall h \geq 2
\end{align*}
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
\begin{align*}
\gamma_y(0) 
&amp;= cov(y_t, y_t)\\ 
&amp;= \frac{1}{4} cov(x_t - x_{t-2}, x_t - x_{t-2})\\ 
&amp;= \frac{1}{4} E(x_tx_t - 2x_t x_{t-2}+x_{t-2}^2) \quad\text{since} x_t \text{ is a lin comb. of} a_t, E(X_t) = 0\\
&amp;=\frac{1}{4}(2\gamma_x(0)) = \frac{\sigma^2}{9}\\
\gamma_y(1) 
&amp;= cov(y_t, y_{t-1})\\
&amp;= \frac{1}{4} cov(x_t - x_{t-2}, x_{t-1} - x_{t-3})\\
&amp;= \frac{1}{4} E(x_tx_{t-1} - x_t x_{t-3} - x_{t-1}x_{t-2}+x_{t-2}x_{t-3})\\
&amp;=\frac{1}{4}(\gamma_x(1)) = \frac{\sigma^2}{36}\\
\gamma_y(2) 
&amp;= cov(y_t, y_{t-2})\\
&amp;= \frac{1}{4} cov(x_t - x_{t-2}, x_{t-2} - x_{t-4})\\
&amp;= \frac{1}{4} E(x_tx_{t-2} - x_t x_{t-4} - x_{t-2}x_{t-2}+x_{t-2}x_{t-4})\\
&amp;=\frac{1}{4}(-\gamma_x(0)) = \frac{-\sigma^2}{18}\\
\gamma_y(3) 
&amp;= cov(y_t, y_{t-3})\\
&amp;= \frac{1}{4} cov(x_t - x_{t-2}, x_{t-3} - x_{t-5})\\
&amp;= \frac{1}{4} E(x_tx_{t-3} - x_t x_{t-5} - x_{t-2}x_{t-3}+x_{t-2}x_{t-5})\\
&amp;=\frac{1}{4}(-\gamma_x(1)) = \frac{-\sigma^2}{36}\\
\gamma_y(h)
&amp;= cov(y_t, y_{t-h})\\
&amp;= \frac{1}{4} cov(x_t - x_{t-2}, x_{t-h-1} - x_{t-h-3})\\
&amp;= \frac{1}{4} E(x_tx_{t-h-1} - x_t x_{t-h-3} - x_{t-2}x_{t-h-1}+x_{t-2}x_{t-h-3})\\
&amp;=0\quad\forall h \geq 4\\
\end{align*}
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>PCAF for $y$</h2>
$$\rho_1 = 1/4, \rho_2 = -1/2, \rho_3 = -1/4$$$$\rho_1 = \phi_{31}\rho_0 + \phi_{32}\rho_1 + \phi_{33}\rho_2$$<p><br>
$$\rho_2 = \phi_{31}\rho_1 + \phi_{32}\rho_0 + \phi_{33}\rho_1$$<br>
$$\rho_3 = \phi_{31}\rho_2 + \phi_{32}\rho_1 + \phi_{33}\rho_0$$ 
$$1/4 = \phi_{31} + 1/4 \phi_{32} -1/2 \phi_{33}$$<br>
$$-1/2 = 1/4\phi_{31} + \phi_{32} + 1/4\phi_{33}$$<br>
$$-1/4 = -1/2\phi_{31} + 1/4\phi_{32} + \phi_{33}$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
\begin{align*}
\gamma_{xy}(0) 
&amp;= cov(x_t, \frac{x_t}{2} - \frac{x_{t-2}}{2})\\ 
&amp;=\frac{1}{2}E(x_tx_t) - \frac{1}{2}{E(x_tx_{t-2})}\\
&amp;= \frac{1}{2}\gamma_x(0) = \frac{\sigma^2}{9}\\
\rho_{xy}(0) 
&amp;= [\frac{\sigma^2}{9}] / \sqrt{\frac{2\sigma^2}{9}\frac{\sigma^2}{9}}= \sqrt2^{-1}\\
\gamma_{xy}(-1) 
&amp;= cov(x_t, \frac{x_{t-1}}{2} - \frac{x_{t-3}}{2})\\
&amp;=\frac{1}{2}E(x_tx_{t-1}) - \frac{1}{2}{E(x_tx_{t-3})}\\
&amp;= \frac{1}{2}\gamma_x(1) = \frac{\sigma^2}{18}\\
\rho_{xy}(0) 
&amp;= [\frac{\sigma^2}{18}] / \sqrt{\frac{2\sigma^2}{9}\frac{\sigma^2}{9}}= (2\sqrt2)^{-1}
\end{align*}
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>ARMA</h1>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Wold decomposition</h2>
<ul>
<li>Any zero-mean process $\{X_t\}$ which is not deterministic can be expressed as a sum of  <ul>
<li>$\{U_t\} $MA($\infty$) process </li>
<li>$\{V_t\}$ a deterministic process which is uncorrelated with $\{U_t\}$</li>
</ul>
</li>
<li><strong>Deterministic</strong> if the values of $V$ are perfectly predictable by its past observations (as an $AR(\infty)$ process)</li>
<li>Wold decomposition implies that any zero mean process can be expressed as the form of ARMA($\infty, \infty$) so we may be able to approximate any data/process by a higher order ARMA(p,q) model</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>ARMA(2, 2)</h2>
<p>Consider an ARMA(2,2) model</p>
<p>Invertible if AR(2) has all roots $|B|&gt;1\Rightarrow 1 - \phi_1 B - \phi_2 B^2 = 0$ have all roots $|B| &gt; 1$<br>
$B = |\frac{\phi_1 \pm \sqrt{\phi_1^2 + 4\phi_2}}{-2\phi_1}| &gt; 1$</p>
<p>Causal if $MA(2)$ has all roots $|B|&gt;1 \Rightarrow 1 + \theta_1 B + \theta_2 B^2$ ...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assume Causal, $x_t=\Psi(B)a_t = \frac{\Theta(B)}{\Phi(B)}a_t$<br>
$\Psi(B)\Phi(B)=\Theta(B)$<br>
$\sum_0^\infty \psi_i B^i (1 + \sum_1^\infty -\phi_i B^i) = \sum_0^\infty \theta_i B^i$</p>
<p>$\psi_1:\psi_1 B - \phi_1 B = \theta_1 B=&gt; \psi_1 = \theta_1 + \phi_1$
$\psi_2: \psi_2 B^2 - \phi_1 B^2 -\psi_1B\phi_1B=\theta_2 B^2\Rightarrow \psi_2 = \theta_2 + \phi_2 + \phi_1(\theta_1 + \phi_1)$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assume invertible, $a_t = \sum_0^\infty \pi_j x_{t-j}=\Pi(B)x_t$
$\Pi(B)\Theta(B)=\Phi(B)$
...</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>Box-Jenkins approach and unit root tests</h1>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>_$x_t = a+\beta t^2 + y_t, y_t = a_t + \theta_1 a_{t-1}, a_t \sim NID(0,1)$. Show we can make $x_t$ stationary by differencing $\{x_t\}$._</p>
<p>Since we want to make $x_t$ independent of $t$, we apply $\nabla^2$</p>
<p>$\nabla^2 x_t = (1-B)^2 x_t$<br>
$=x_t - 2Bx_t + B^2 x_t$<br>
$=a + \beta t^2 + y_t - 2(a + \beta(t-1)^2 + y_{t-1}) + (a + \beta(t-2)^2 + y_{t-2})$<br>
$=(1-2+1)a + \beta (t^2 - 2(t-1)^2 + (t-2)^2) + y_t - 2y_{t-1} + y_{t-2}$<br>
$=2\beta + y_t - 2y_{t-1}+y_{t-2}$</p>
<p>Since $\beta$ is constant, $y_t$ is a lin. comb. of $a_t$, it is stationary</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>_$x_t = \mu + x_{t-1} + a_t + \theta a_{t-1}, a_t \sim NID(0,1), x_0 \sim NID(\mu, \sigma^2), \forall \tau &lt; 0. a_\tau = x_\tau = 0$_</p>
<p>Then, we can use substitution to substitute $x_{t-1} = \mu + x_{t-2} + a_{t-1} + \theta a_{t-2}$ and so on, and since $x_{-1} = 0$<br>
$x_t = \mu t + \sum^t_0 a_t + \sum_0^{t-1}\theta a_i$<br>
Therefore, $\theta^*_j = \begin{cases}1 &amp; j = 0 \\ 1 + \theta &amp; 1\leq j \leq t \end{cases}$</p>

</div>
</div>
</div>
 

