---
title: Computer Arithmetic
order: 20
---
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>Integers</h1>
<p>The only issue is <strong>overflow</strong>, and the issue with division (Euclidean division or floating depends on algorithms)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>floating-point numbers</h1>
<p>Often approximates reals</p>
<h2>Representation of floating numbers</h2>
<p>$\pm d_1.d_2d_3d_4...d_p \times \beta^n \equiv $ [significant/fraction part/mantissa] $\times$ [exponent] where<br>
$\beta$: base,<br>
$p$: procession,<br>
$0\leq d_i &lt; \beta$<br>
If normalized, $d_1 \neq 0$<br>
$L \leq n \leq U$</p>
<p><strong>Underflow limit (UFL)</strong> the smallest positive number before getting a underflow is $1.00..0 \times \beta^L$
<strong>Overflow limit (OFL)</strong> the largest positive number before getting an overflow is $[\beta-1].[\beta-1]...[\beta-1] \times \beta^U = (\beta - \beta^{1-p})\times \beta^U = (1-\beta^{-p})\beta^{U+1}$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>IEEE Floating Point Standard</h2>
<table>
<thead><tr>
<th></th>
<th>p</th>
<th>L</th>
<th>U</th>
<th>decimal numbers</th>
<th>exponent range in base 10</th>
</tr>
</thead>
<tbody>
<tr>
<td>single precision</td>
<td>24</td>
<td>-126</td>
<td>127</td>
<td>6-7</td>
<td>-37 ~ +37</td>
</tr>
<tr>
<td>double precision</td>
<td>53</td>
<td>-1022</td>
<td>1023</td>
<td>16</td>
<td>-308 ~ +308</td>
<td></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Rounding</h2>
<p>Most of the time, we can round to the nearest, while when the rounding is exactly at the middle, round to the nearest even least-significant-digit (<strong>round to even</strong>). In binary, such case will always round to 0 (as 0 is "even")</p>
<p>IEEE has 4 rounding modes, but we will only encounter rounding to the nearest.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Example</strong> Consider 3 decimal digit numbers, i.e. $(p = 3, \beta = 10)$, assume $L,U = [-10, 10]$. Then 
$$1.54\times 10^1 + 2.56\times 10^{-1} = 15.4 + 0.256 = 15.656 \rightarrow 1.57 \times 10^1$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Distance between two adjacent floating number =&gt; Machine epsilon $\epsilon_{mach}$</h2>
<p>The distance from 1 to the next bigger floating-point number will be $1.00...0 \times \beta^0$, the next number will be $1.00...01\times \beta^0$, $d=\beta^{1-p}=:\epsilon_{mach}$, which is the machine epsilon.</p>
<p>For each adjacent pair of numbers $a, b$ in $[\beta^i, \beta_{i+1}), d(a, b) = \beta^i \epsilon_{mach}$, a.k.a. numbers are evenly spread with tte distance apart $=\beta^i \epsilon_{mach}$</p>
<p>For some real number $a$, considering the rounding to the nearest floating point number, the absolute error $FP(a)$, $|fl(a) - a| \leq \frac{\beta^i\epsilon_{mach}}{2}$ and the relative error $\frac{|fp(a)-a|}{|a|}\leq \frac{\beta^i\epsilon_{mach}}{2\beta^i} = \epsilon_{mach}/2$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>IEEE Rule of operations</h1>
<p>IEEE has 5 <strong>Basic operations</strong>: $+,-,\times, /, \sqrt{x} $ and guarantees that</p>
<p>$fl(a \: op\: b):=$ the floating point number closest to $a\: op\:b$, assuming using rounding to nearest mode and not exceeding UFL or OFL</p>
<p>$\Rightarrow |\frac{fl(a\: op\: b) - (a\: op\: b)}{a\: op\: b}| \leq \frac{\epsilon_{mach}}{2}$</p>
<p>If encounters UFL or OFL, this property may not be guaranteed<br>
$$fl(2.02\times 10^{-16}\times 1.11\times 10^{-6}) \rightarrow 0.02\times 10^{-10}$$ 
$$\frac{|2.00\times 10^{-12} - 2.2422\times 10^{-12}|}{2.2422\times 10^{-12}} \approx 0.108 &gt; \frac{1}{2}10^{-2}=\epsilon_{mach}/2$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Problems with $\geq 2$ numbers</h2>
<p>Consider $fl(1.00\times 10^3 + 1.00\times 10^7 - 1.00\times 10^7)$, for exact arithmetic the result will be $1.0001\times 10^7$, 
while if we do the calculate in the left-right order $fl(*) = fl(1.00\times 10^7 - 1.00\times 10^7) = 0$<br>
if we do the subtraction first, the result will be $fl(1.00\times 10^3 + 0) = 1.00\times 10^3$</p>
<p><strong>Catastrophic cancellation</strong> If you compute a sum and some of the intermediate values are much larger in magnitude than the final result, then the relative error in the computed sum may be very large. (Consider the example given, $\frac{|0 - T|}{T} = 1\Rightarrow $ no accuracy at all)</p>
<p>Consider $fl((a*b)*c)$, assuming no OFL/UFL, since $fl(a*b) = (a*b)(1+\delta), |\delta| \leq \epsilon_{mach}/2$. Then, 
$$\begin{align}
fl(a*b*c) &amp;= fl((a*b)(1+\delta)*c) \\
&amp;= [(ab)(1+\delta_1)]c(1+\delta_2)\\
&amp;= (abc)(1+\delta_1+\delta_2 + \delta_1\delta_2)\\
&amp;\leq (abc)(1+\epsilon_{mach} + \epsilon^2_{mach}/4)\\
\frac{fl(a*b*c) - abc}{abc}&amp;= \epsilon + \epsilon^2/4
\end{align}$$
Therefore, multiplications often have fewer errors</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Suppose $a,b,c\geq 0$ (also works on $a,b,c\leq 0$), assume no OFL/UFL<br>
$$\begin{align}
fl(a+b+c) &amp;= fl((a+b)(1+\delta)+c)\\
&amp;= ((a+b)(1+\delta_1) + c)(1+\delta_2)\\
&amp;= ((a+b+c)(1+\hat\delta_1))(1+\delta_2)&amp;\text{take }\hat\delta_1 *\\
&amp;= (a+b+c)(1+\hat\delta_1)(1+\delta_2)\\
&amp;= (a+b+c)(1+\tilde \delta)
\end{align}$$</p>
<p><strong>Claim</strong> $*\: |\hat\delta_1|\leq \epsilon/2$<br>
$$\begin{align*}(a+b)(1+\delta_1)+c &amp;\leq (a+b)(1+\epsilon/2) + c&amp;a,b,c\geq 0\\
&amp;\leq (a+b+c)(1+\epsilon/2)\\
(a+b)(1-\delta_1)+c&amp;\geq (a+b)(1-\epsilon/2)+c \\&amp;\geq (a+b+c)(1-\epsilon/2)
\end{align*}$$</p>
<p><strong>Note</strong> $a,b,c$ must have the <strong>same sign</strong> to make this true</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Computing infinite sum</h2>
$$fl(\sum^\infty n^{-1}) = fl(\sum^N \frac{1}{n} + \frac{1}{N+1})$$<p>However, $\frac{1}{N+1}$ will cause a UFL, hence $fl(*)$ gives a finite result instead of $\infty$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Example</strong> $\beta = 10, p =3, L= -10, U = 10$<br>
IEEE guarantees that we can always get the exact value, then do the rounding
$$fl(3.67\times 10 + 4.56 \times 10^2) = fl(36.7 + 456) = fl(492.7) = 4.93\times 10^2$$
Could have underflow
$$fl(2.02\times 10^{-6} \times 1.01\times 10^{-5}) = fl(2.0402\times 10^{-11})=UFL$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Subnormal (denormal) numbers and Gradual Underflow</h2>
<p>Subnormal numbers have $d_1 = 0$.<br>
Benefit: We filled in the gap between $[0, \beta^L)$<br>
Penalty: The machine epsilon number rule does not hold, i.e. $\exists a. |fl(a)-a|/|a| &gt; \epsilon_{mach}/2$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Example</strong> with $\beta = 10, p = 3, L = -10, U = 10$</p>
$$\begin{align}
1.01 \times 10^{-5} \cdot 2.02 \times 10^{-6} &amp;= 2.0402 \times 10^{-11}\\
&amp;= 0.20402\times 10^{-10} &amp;\text{using subnormal}\\
&amp;\rightarrow 0.20\times 10^{-10} &amp;\text{still need leading 0 to tell this is subnormal} \\
1.01 \times 10^{-6} \cdot 2.02 \times 10^{-7} &amp;= 2.0402 \times 10^{-13}\\
&amp;= 0.0020402\times 10^{-10} \\
&amp;\rightarrow 0.00\times 10^{-10} &amp;\text{underflow}\\
&amp;\rightarrow 0
\end{align}$$<p>The second case will be the underflow to a subnormal number</p>
$$\begin{align}
3.56 \times 10^6 \cdot 5.41 \times 10^6 &amp;= 1.92596 \times 10^{11}\\
&amp;\rightarrow +Inf &amp;\text{overflow happens}
\end{align}$$<h2>Inf and NaN</h2>
<p>When overflow happens, IEEE rules it as $\pm Inf$ (it just means greater than the computer's capacity, not actually infinity)<br>
$Inf  + Inf\rightarrow +Inf, Inf-Inf\rightarrow NaN, Inf/Inf \rightarrow NaN, 0/0\rightarrow NaN$ <code>NaN</code> better understands as I don't know what it is</p>

</div>
</div>
</div>
 

