{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Probabilistic Models\n",
    "order: 70\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Function\n",
    "The density of the observed data, as a function of parameters $\\theta$. \n",
    "\n",
    "## Approaches to classification\n",
    "__Discriminative approach__ estimate parameters of decision boundary / class separator directly from labeled examples\n",
    " - How do I separate the classes\n",
    " - learn $p(t|x)$ directly (logistic regression models)\n",
    " - learn mapping from inputs to classes\n",
    " \n",
    "__Generative approach__ model the distribution of inputs characteristic of the class (Bayes classifier)\n",
    " - What does each class \"look\" like?\n",
    " - Build a model of $p(x|t)$\n",
    " - Apply Bayes rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Classifier\n",
    "Given features $x = [x_1,...,x_D]^T$, we want to compute class probabilities using Bayes Rule:\n",
    "$$p(c|x) = \\frac{p(x,c)}{p(x)} = \\frac{p(x|c)p(c)}{p(x)}$$\n",
    "or by text $$\\text{posterior} = \\frac{\\text{class likelihood} \\times {\\text{prior}}}{\\text{Evidence}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Nets\n",
    "We can represent this model using an __directed graphical model__, or __Bayesian network__. \n",
    "\n",
    "This graph structure means the joint distribution factorizes as a product of conditional distribution for each variable given its parent(s). \n",
    "\n",
    "Intuitively, you can think of the edges as reflecting a causal structure. But mathematically, this doesn't hold without additional assumptions. \n",
    "\n",
    "The parameters can be learned efficiently because the log-likelihood decomposes into independent terms for each feature. \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal l(\\theta) &= \\sum_{i=1}^N \\log p(c^{(i)}, x^{(i)})\\\\\n",
    "&= \\sum_{i=1}^N \\log\\{p(x^{(i)}| c^{(i)})p(c^{(i)})\\}\\\\\n",
    "&= \\sum_{i=1}^N \\log\\{p(c^{(i)}) \\prod_{j=1}^D p(x_j^{(i)}| c^{(i)})\\}\\\\\n",
    "&= \\sum_{i=1}^N \\bigg[\\log p(c^{(i)}) + \\sum_{j=1}^D \\log p(x_j^{(i)}|c^{(i)})\\bigg]\\\\\n",
    "&= \\underset{\\text{Bernoulli log-likelihood of labels}}{\\sum_{i=1}^N \\log p(c^{(i)})} + \\underset{\\text{Bernoulli log-likelihood for feature }x_j}{\\sum_j^D\\sum_i^N \\log p(x_j^{(i)}|c^{(i)})}\n",
    "\\end{align*}\n",
    "\n",
    "Each of these log-likelihood terms depends on different set of parameters, so they can be optimized independently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Inference\n",
    "$$p(c|x)\\propto p(c)\\prod_j^D p(x_j|c)$$\n",
    "For input $x$, predict by comparing the values of $p(c)\\prod_j^D p(x_j|c)$ for different $c$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Parameter Estimation\n",
    "Bayesian approach treats the parameters as random variables. $\\beta$ is the set of parameters in the prior distribution of $\\theta$\n",
    "\n",
    "To define a Bayesian model, we need to specify two distributions:  \n",
    "__prior distribution__$p(\\theta)$, which encodes our beliefs about the parameters __before__ we observe the data.  \n",
    "__likelihood__, same as in MLE\n",
    "\n",
    "When we update our beliefs based on the observations, we compute the __posterior distribution__ using Bayes' rule. \n",
    "$$p(\\theta|\\mathcal D) = \\frac{p(\\theta)p(\\mathcal D|\\theta)}{\\int p(\\theta')p(\\mathcal D|\\theta')d\\theta'}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum A-Posteriori Estimation\n",
    "Find the most likely parameter settings under the posterior\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\boldsymbol{\\theta}}_{\\mathrm{MAP}}&=\\arg \\max _{\\boldsymbol{\\theta}} p(\\boldsymbol{\\theta} | \\mathcal{D}) \\\\\n",
    "&=\\arg \\max _{\\boldsymbol{\\theta}} p(\\boldsymbol{\\theta}) p(\\mathcal{D} | \\boldsymbol{\\theta})  \\\\\n",
    "&=\\arg \\max _{\\boldsymbol{\\theta}} \\log p(\\boldsymbol{\\theta})+\\log p(\\mathcal{D} | \\boldsymbol{\\theta})$\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Gaussian Discriminant Analysis (Gaussian Bayes Classifier)\n",
    "\n",
    "Make decisions by comparing class posteriors. \n",
    "$$\\log p\\left(t_{k} | \\mathbf{x}\\right)=\\log p\\left(\\mathbf{x} | t_{k}\\right)+\\log p\\left(t_{k}\\right)-\\log p(\\mathbf{x})$$\n",
    "Expanded as \n",
    "\\begin{align*}\\log p\\left(t_{k} | \\mathbf{x}\\right) =  &-\\frac{d}{2} \\log (2 \\pi) -\\frac{1}{2} \\log \\left|\\boldsymbol{\\Sigma}_{k}^{-1}\\right| \\\\\n",
    "&-\\frac{1}{2}\\left(\\mathbf{x}-\\boldsymbol{\\mu}_{k}\\right)^{T} \\boldsymbol{\\Sigma}_{k}^{-1}\\left(\\mathbf{x}-\\boldsymbol{\\mu}_{k}\\right) \\\\\n",
    "&+\\log p\\left(t_{k}\\right)-\\log p(\\mathbf{x})\n",
    "\\end{align*}\n",
    "Decision Boundary \n",
    "\\begin{align*}&\\log p\\left(t_{k} | \\mathbf{x}\\right)=\\log p\\left(t_{l} | \\mathbf{x}\\right) \\\\\\Rightarrow &\\left(\\mathbf{x}-\\boldsymbol{\\mu}_{k}\\right)^{T} \\boldsymbol{\\Sigma}_{k}^{-1}\\left(\\mathbf{x}-\\boldsymbol{\\mu}_{k}\\right)=\\left(\\mathbf{x}-\\boldsymbol{\\mu}_{\\ell}\\right)^{T} \\boldsymbol{\\Sigma}_{\\ell}^{-1}\\left(\\mathbf{x}-\\boldsymbol{\\mu}_{\\ell}\\right)+C_{k, l} \\\\\\Rightarrow&\\mathbf{x}^{T} \\boldsymbol{\\Sigma}_{k}^{-1} \\mathbf{x}-2 \\boldsymbol{\\mu}_{k}^{T} \\mathbf{\\Sigma}_{k}^{-1} \\mathbf{x}=\\mathbf{x}^{T} \\mathbf{\\Sigma}_{\\ell}^{-1} \\mathbf{x}-2 \\boldsymbol{\\mu}_{\\ell}^{T} \\mathbf{\\Sigma}_{\\ell}^{-1} \\mathbf{x}+C_{k, l}\n",
    "\\end{align*}\n",
    "Decision Boundary is quadratic since gaussian is quadratic. When we have to humps that share the same covariance, the decision boundary is linear. \n",
    "\n",
    "## Properties of Gaussian Distribution\n",
    "$\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\mathbf{\\Sigma})$ is defined as \n",
    "$$p(\\mathbf{x})=\\frac{1}{(2 \\pi)^{d / 2}|\\mathbf{\\Sigma}|^{1 / 2}} \\exp \\left[-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^{T} \\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})\\right]$$\n",
    "__Empirical Mean__ $\\hat{\\boldsymbol{\\mu}}=\\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{x}^{(i)}$  \n",
    "__Empirical Covariance__ $\\hat{\\mathbf{\\Sigma}}=\\frac{1}{N} \\sum_{i=1}^{N}\\left(\\mathbf{x}^{(i)}-\\hat{\\boldsymbol{\\mu}}\\right)\\left(\\mathbf{x}^{(i)}-\\hat{\\boldsymbol{\\mu}}\\right)^{\\top}$\n",
    "\n",
    "\n",
    "## GDA vs.  Logistic Regression\n",
    "- GDA is generative while LR is discriminative model. \n",
    "- GDA makes stringer modelling assumptions: assumes gaussian distributon. When assumption true, GDA asymptotically efficient. - - LR more robust, less sensitive to incorrect modelling assumptions (LR uses CE, no assumption.) \n",
    "- Class-conditional distributions usually lead to logistic classifier. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
