{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Forecasting and Transfer Function Noise model\n",
    "order: 30\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimized MSE Forecasts for ARMA models\n",
    "Consider a stationary ARMA model (casual and invertible)  \n",
    "$$\\Phi(B)X_t = \\Theta(B)a_t$$  \n",
    "Rewrite as a MA process\n",
    "$$X_t = \\Psi(B)a_t$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for $t = n + h$, \n",
    "$$X_{n+h}=\\sum^\\infty_0 \\psi_i a_{n+ h - i}$$\n",
    "Suppose we have observations till $X_n, X_{n-1},...$ and wish to forecast $h$ step ahead of future values $X_{n+h}$ as a lin.comb. of the observations. Then, we define the mean square error forecaster \n",
    "$$\\hat X_t(h):= \\sum_{i=0}^\\infty \\hat\\psi_i a_{t-i}$$\n",
    "where $\\hat\\psi_i$ are parameters to be determined.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then MSE of the forecast is   \n",
    "$E(X_{t+h} - \\hat X_t(h))^2  = E(\\sum^\\infty \\psi_i a_{t+h-i} - \\sum^\\infty \\hat\\psi_i a _{t-i})$  \n",
    "$= E(\\sum^{j-1}\\psi_i a_{t+h-i}) + \\sum^\\infty (\\psi_{h+i} + \\hat\\psi_i)a_{t-i})^2$  \n",
    "$= \\sigma^2 \\sum^{h-1} \\psi_i^2 + \\sigma^2 \\sum^\\infty (\\psi_{h+i-\\hat\\psi_i})^2$  \n",
    "\n",
    "$argmin(E(X_{t+h} - \\hat X_t(h))^2)=argmin(\\sum^\\infty (\\psi_{h+i-\\hat\\psi_i})^2)$  \n",
    "$\\Rightarrow \\psi_{h+i} = \\hat\\psi_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule of calculating conditional expectation\n",
    "$$E_t(X_{t+h}) := E(X_{t+h}\\mid X_t, X_{t-1}, ...) = E(\\sum^\\infty \\psi_i a_{t+h-i}\\mid X_t, X_{t-1},...)$$\n",
    "Using the fact that $a_i$'s are uncorrelated\n",
    "$$E(X_{t+h}\\mid X_t, X_{t-1}, ...) =\\sum^\\infty \\psi_{h+i}a_{t-i} = \\hat X_t(h)$$\n",
    "\n",
    "For $h > 0$, \n",
    "$$E_t(X+h) = \\hat X_t (h)$$\n",
    "$$E_t(X_{t-h}) = X_{t-h}$$\n",
    "$$E_t(a_{t+h})=E(a_{t+h}) = 0$$\n",
    "$$E_t(a_{t-h}) = X_{t-h} - \\hat X_{t-h-1} = X_{t-h} - E_{t-h-1}(X_{t-h})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Consider a AR(1) model $X_t = 0.5X_{t-1} + a_t$. Then  \n",
    "$$\\hat X_t(1)  = E_t(X_{t+1}) = 0.5 E_t(X_t) + E_t(a_{t+1}) = 0.5E_t(X_t) = 0.5X_t$$ \n",
    "$$\\hat X_t(h) = 0.5 E_t(X_{t+h-1}) + E_t(a_{t+h}) = 0.5 \\hat X_t(h-1) = 0.5^h X_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Function Noise model\n",
    "Consider the model that \n",
    "$X_t = f(X_{t-1}, X_{t-2}, ... , Z_t, Z_{t-1},...)$, $X_t$ is a linear combination of past observations and an external variable.\n",
    "\n",
    "A TFN model is a time series regression that predict values of a dependent variable based on both the current and lagged values of one or more explanatory variables.\n",
    "\n",
    "## Procedure of building the single input TFN model\n",
    "1. Preliminary identification of the impulse response coefficients $v_i$ (prewhitening)\n",
    "2. Specification of the noise term $n_t$\n",
    "3. Specification of the transfer function using a rational polynomial in B if necessary\n",
    "4. Estimation of the TFN specified \n",
    "5. Model diagnostic checks\n",
    "\n",
    "__Rational distributed lag model__\n",
    "$v(B)$ can be approximated by a ratio of polynomials  \n",
    "$$v(B)=\\frac{\\sum_0^r\\delta B^i}{1-\\sum_1^s\\theta_i B^i} = \\delta(B)/\\theta(B)$$\n",
    "and then, $y_t = \\delta(B)x_t / \\theta(B) + n_t$\n",
    "\n",
    "## ARMAX\n",
    "$y_t = v(B)x_t + n_t = v_0 x_t + v_1 x_{t-1}+v_2 x_{t-2}+...+n_t$  \n",
    "where $v(B) = \\sum^\\infty v_j B^j$, and $x_t,n_t$ are independent. \n",
    "\n",
    "The coefficient $v_0, v_1,...$ are referred as the impulse response function of the system.\n",
    "\n",
    "To make such equation to be meaningful, $\\sum^\\infty |v_j| = g<\\infty$, which the system is stable and $g$ is called the stead-state gain. $g$ represents the impact on $Y$ when $X_{t-j}$ are held constant over time.  \n",
    "\n",
    "__Properties__   \n",
    "$x_t \\sim ARMA(p,q)$, $v_i = \\phi^i (1-\\phi)$, $y_t = \\sum^\\infty v_i x_{t-i}+a_t$\n",
    "\n",
    "## Pre-whitening\n",
    "Consider $x\\sim $ARMA, i.e. $\\Phi_x(B)x_t = \\Theta_x(B)a_t$  \n",
    "Apply $\\Phi_x(B)/\\Theta_x(B)$ on TFN model  \n",
    "$\\frac{\\Phi_x(B)}{\\Theta_x(B)}y_t = v(B)\\frac{\\Phi_x(B)}{\\Theta_x(B)} x_t + \\frac{\\Phi_x(B)}{\\Theta_x(B)}\\epsilon_t$  \n",
    "Let $\\tau_t = \\frac{\\Phi_x(B)}{\\Theta_x(B)} y_t, n_t = \\frac{\\Phi_x(B)}{\\Theta_x(B)} \\epsilon_t$, we get   \n",
    "$\\tau_t = v(B)a_t + n_t$ and $n_t$ is independent of $a_t$  \n",
    "\n",
    "To get $\\gamma_{a\\tau}(0)$, multiply both sides by $a_t$ and take the expectations. \n",
    "$\\gamma_{a\\tau}(0)=E(a_t\\tau_t) = E(a_tv(B)a_t) + E(a_tn_t)$  \n",
    "$=E((v_0a_t + v_1e_{t-1}+...+v_ma_{t-m})a_t)$  \n",
    "$=E(v_0a_ta_t)=v_o\\gamma_a(0) = v_0\\sigma^2$\n",
    "\n",
    "To get $\\gamma_{a\\tau}(1)$, multiply both sides by $a_{t-1}$  \n",
    "$\\gamma_{a\\tau}(1)=E(a_{t-1}\\tau_t) =E(a_{t-1}v(B)a_t) + E(a_{t-1}n_t)$   \n",
    "$=E(a_{t-1}(v_0a_t + v_1 a_{t-1} + v_2 a_{t-2}+...+v_m a_{t-m}))$  \n",
    "$= E(a_{t-1}v_1 a_{t-1})=v_1\\gamma_a(0) = v_1\\sigma^2$\n",
    "\n",
    "Therefore, $\\gamma_{a\\tau(k)} = v_k\\sigma^2$\n",
    "\n",
    "Since $\\rho_{a\\tau}(k) = \\gamma_{a\\tau}(k) / \\sigma_a\\sigma_\\tau$  \n",
    "$\\rho_{a\\tau}(k) = \\frac{v_k \\sigma_a^2}{\\sigma_a\\sigma_\\tau} = \\frac{v_k \\sigma_a}{\\sigma_\\tau}$  \n",
    "and $v_k = \\rho_{a\\tau}(k)\\frac{\\sigma_\\tau}{\\sigma_a}\\propto \\rho_{a\\tau}(k)$\n",
    "\n",
    "## Box-Tiao Transformation\n",
    "\n",
    "\n",
    "Similarly, since $n_t\\sim$ ARMA, i.e. $\\Phi_n(B)n_t = \\Theta_n(B)a_t$  \n",
    "Which $\\frac{\\Phi_n(B)}{\\Theta_n(B)}n_t = a_t$  \n",
    "Then, apply $\\frac{\\Phi_n(B)}{\\Theta_n(B)}$ to both sides of the equation. \n",
    "$$\\frac{\\Phi_n(B)}{\\Theta_n(B)} y_t = v(B) \\frac{\\Phi_n(B)}{\\Theta_n(B)} x_t + $\\frac{\\Phi_n(B)}{\\Theta_n(B)} n_t$$\n",
    "$$\\tilde y_t = v(B)\\tilde x_t + a_t$$\n",
    "is called the Box-Tiao Transformation\n",
    "\n",
    "## Steps of The Estimation Procedure\n",
    "The steps of the estimation procedures\n",
    "1. Run the OLS regression on $y_t = \\sum_{j=1}^s v_j x_{t-j} + e_t$ to collect the residuals $\\{\\hat e_t\\}$\n",
    "2. Identify an ARMA model for $\\hat e_t$ \n",
    "3. Apply Box-Tiao transformation to filter $y_t, x_t$\n",
    "4. Run regression on the transformed equation\n",
    "5. check the correlation of regression residuals "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
