{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoregressive(AR) and moving average(MA) model \n",
    "A process $\\{X_t\\}$ is said to be an ARMA(p,q) process if \n",
    " - $\\{X_t\\}$ is stationary\n",
    " - $\\forall t. X_t - \\phi_1X_{t-1}-...-\\phi_qX_{t-p} = a_t + \\theta_1a_{t-1}+...+\\theta_qa_{t-q}$  \n",
    " using backward shift operation notation $B^h=x_{t-h}$:  \n",
    " $\\Phi(B)x_t = (1-\\phi_1B - ... - \\phi_p B^p)x_t = (1+\\theta_1B + ...+\\theta_qB^q)a_t = \\Theta(B)a_t$\n",
    " where $a_t \\sim NID(0, \\sigma^2)$  \n",
    " \n",
    "$\\{X_t\\}$ is an ARMA(p,q) process with mean $\\mu$ if $\\{X_t-\\mu\\}$ is an ARMA(p,q) process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving average model(MA(q))\n",
    "__MA($\\infty$)__ If $\\{a_t\\}\\sim NID(0, \\sigma^2)$ then we say that $\\{X_t\\}$ is a MA($\\infty$) process of $\\{a_t\\}$ if $\\exists\\{\\psi_n\\}, \\sum^\\infty |\\psi_j|<\\infty$ and $X_t = \\sum^\\infty \\psi_j a_{t-j}$ where $t\\in\\mathbb{Z}$.  \n",
    "\n",
    "We can calculate ACF of a stochastic process $\\{X_t\\}$ a.l.s. $\\{X_t\\}$ can be writtin in the form of a MA($\\infty$) process\n",
    "\n",
    "Also, MA($\\infty$) is a required condition for $\\{X_t\\}$ to be stationary. \n",
    "\n",
    "__Theorem__  The MA($\\infty$) process is stationary with 0 mean and autocovariance function $\\gamma(k) = \\sigma^2 \\sum^\\infty \\psi_j\\psi_{j+|k|}$ \n",
    "\n",
    "__MA(q)__ $X_t = \\sum_{i=0}^q \\theta_i a_{t-i} = \\Theta(B)a_t$  $\\theta_0 = 1, B$ is the backward shift operator, $B^hX_t = X_{t-h}$ and $a_t\\sim NID(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under MA(q) model  \n",
    "$\\gamma(1) = cov(X_t, X_{t+1})$  \n",
    "$=cov(\\sum_{i=0}^q\\theta_i a_{t-i}, \\sum_{i=0}^q \\theta_ia_{t+1-i})$  \n",
    "$=E(\\sum_{i=0}^{q-1}\\theta_i\\theta_{i+1}a_{t-i}a_{t-i})$ since $a\\sim NID, cov(a_i,a_j) =0$  \n",
    "$=\\sigma^2(\\sum_{i=0}^{q-1}\\theta_i\\theta_{i+1})$\n",
    "\n",
    "Similarly,  \n",
    "$\\gamma(k)=cov(X_t, X_{t+k})$  \n",
    "$=cov(\\sum_{i=0}^q \\theta_t a_{t-i}, \\sum_{i=0}^q \\theta_i a_{t+k - i})$  \n",
    "$=\\sigma^2 \\sum_{i=0}^{q-k}\\theta_i\\theta_{i+k}\\mathbb{I}(|k|\\leq q)$\n",
    "\n",
    "Then, the autocorrelation function (ACF) will be  \n",
    "$\\rho_k = \\gamma_k/\\sqrt{var(X_t)var(X_{t+k})}$  \n",
    "$ = \\gamma_k / \\sigma^2\\sum_{i=0}^{q} \\theta_i^2$  \n",
    "$=\\sigma^2 \\sum_{i=0}^{q-k}\\theta_i\\theta_{i+k}\\mathbb{I}(|k|\\leq q) / \\sigma^2\\sum_{i=0}^{q} \\theta_i^2$  \n",
    "$= \\sum_{i=0}^{q-k}\\theta_i\\theta_{i+k}\\mathbb{I}(k\\leq q) / \\sum_{i=0}^{q} \\theta_i^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoregressive model of order p (AR(p))\n",
    "$X_t - \\phi_1X_{t-1}-...-\\phi_pX_{t-p} = \\Phi(B)X_t = a_t$  \n",
    "where $a_t\\sim NID(0, \\sigma^2), B^hX_t = X_{t-h}, h\\in\\mathbb{Z}, \\Phi(B)=(1-\\phi_1B-...-\\phi_p B^p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR(1)\n",
    "Notice that for a $AR(1)$ process, $a\\sim NID(0, \\sigma^2)$ and $a_t$ is uncorrelated with all previous $X_s, s<t$\n",
    "\n",
    "$X_t = \\phi X_{t-1} + a_t$  \n",
    "$=\\phi(\\phi X_{t-2}+a_{t-1})+a_t$ replace $X_{t-1}$  \n",
    "$...$ repeated replacing   \n",
    "$=\\sum_0^\\infty \\phi^i a_{t-i}$\n",
    "is a $MA(\\infty)$ process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma(k) = cov(X_t, X_{t+k})$  \n",
    "$=cov(\\sum_0^\\infty \\phi^i a_{t-i}, \\sum_0^\\infty \\phi^i a_{t+k-i})$  \n",
    "$=cov(\\sum_0^\\infty \\phi^i a_{t-i}, \\sum_0^\\infty \\phi^{i+k} a_{t-i} + \\sum_0^{k-1} \\phi^i a_{t+k-i})$  \n",
    "$= \\phi^k\\sum_0^\\infty (\\phi^ia_{t-i})^2$  \n",
    "$=\\phi^k \\gamma(0)=\\phi^k var(X_t)$\n",
    "\n",
    "$\\gamma(0)=var(X_t)=\\sum^\\infty \\phi^{2i}a^2_{t-i}$  \n",
    "$=\\sigma^2(\\sum^\\infty (\\phi^2)^i)$ since $a\\sim NID(0,\\sigma^2)$  \n",
    "$=\\sigma^2(1-\\phi^2)^{-1}$ when $\\phi^2<1$ by Maclaurin's series\n",
    "\n",
    "__Causal__ or future independent AR process when $|\\phi|< 1$ for an $AR(1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking stationarity of AR(p)\n",
    "$\\Phi(B) = 1-\\phi_1B-...-\\phi_pB^p=0$ must have all the roots line outside the unit circle. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACF \n",
    "__AR(1)__ case  \n",
    "$X_t = \\phi X_{t-1} + a_t, a_t\\sim NID(0,\\sigma^2)$  \n",
    "For $k\\in\\mathbb{Z}^+$, multiply $X_{t-k}$ on both sides  \n",
    "$X_t X_{t-k} = \\phi X_{t-1}X_{t-k} + a_t X_{t-k}$   \n",
    "Taking expectation  \n",
    " - consider $E(a_tX_{t-k})$  \n",
    " $cov(a_t, X_{t-k}) = E(a_t X_{t-k})-E(a_t)E(X_{t-k})$  \n",
    " $cov(a_t, X_{t-k}) = E(a_t X_{t-k}) - 0$  \n",
    " $cov(a_t, X_{t-k}) = cov(a_t, \\sum_0^\\infty \\phi^i a_{t-k-i}) = 0$ $a_t$ is uncorrelated with previous $a$'s. \n",
    " \n",
    "$E(X_t X_{t-k}) = \\phi E(X_{t-1}X_{t-k})$  \n",
    "since $cov(X_t,X_{t-k}) = E(X_tX_{t-k})-0$  \n",
    "$\\gamma(k)=\\phi\\gamma(k-1)$  \n",
    "By induction, $\\gamma(k)=\\phi^k\\gamma(0)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__AR(2)__ case  \n",
    "$X_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + a_t$  \n",
    "\n",
    "Multiple both sides by $X_t$  \n",
    "$X_t^2 = \\phi_1 X_{t-1}X_t + \\phi_2 X_{t-2}X_t + X_t a_t$  \n",
    "Taking expectation, note that $X_t$ is a lin.comb of $a$.   \n",
    "$\\gamma(0) = \\gamma(1) + \\gamma(2) + \\sigma^2$    \n",
    "$\\gamma(0)(1-\\phi_1\\rho(1)-\\phi_2\\rho(2)) = \\sigma^2$ since $\\rho(k)=\\gamma(k)/\\gamma(0)$  \n",
    "\n",
    "Multiple both sides by $X_{t-1}$ and take expectations\n",
    "$E(X_tX_{t-1}) = \\phi_1 E(X_{t-1}X_{t-1}) + \\phi_2E(X_{t-2}X_{t-1}) + E(a_t X_{t-1})$  \n",
    "$\\gamma(1) = \\phi_1\\gamma(0) + \\phi_2\\gamma(1)$  \n",
    "$\\rho(1) = \\phi_1 + \\phi_2\\rho(1)$  \n",
    "$\\rho(1) = \\frac{\\phi_1}{1-\\phi_2}$  \n",
    "\n",
    "Multiple both sides by $X_{t-2}$ and take expectations\n",
    "$E(X_tX_{t-2}) = \\phi_1 E(X_{t-1}X_{t-2}) + \\phi_2E(X_{t-2}X_{t-2}) + E(a_t X_{t-2})$  \n",
    "$\\gamma(2) = \\phi_1\\gamma(1) + \\phi_2\\gamma(0)$  \n",
    "$\\rho(2) = \\phi_1\\rho(1) + \\phi_2$  \n",
    "\n",
    "... Using this pattern  \n",
    "$$\\rho(h) = \\phi_1\\rho(h-1)+\\phi_2\\rho(h-2)$$\n",
    "with base case \n",
    "$$\\rho(0)=1, \\rho(1) = \\frac{\\phi_1}{1-\\phi_2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__AR(p)__ case\n",
    "Given $X_t = (\\sum_1^p \\phi_iX_{t-i}) + a_t$, is stationary is all $p$ roots lie outside of the unit circle  \n",
    "\n",
    "__Yule-Walker equations__  \n",
    "For the first $p$ autocorrelations:\n",
    "$\\rho(k) = \\sum_1^p \\phi_i\\rho_{|k-i|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial Autocorrelation Function (PACF)\n",
    "\n",
    "$\\phi_{kk} = corr(X_t, X_{t+k}\\mid X_{t+1},...,X_{t+k-1})$  \n",
    "the correlation between $X_t, X_{t+k}$ after their mutual linear dependency on the intervening variables has been removed. \n",
    "\n",
    "For a given lag $k$, $\\forall j \\in \\{1,2,...,k\\}$.  \n",
    "$$\\rho_i = \\sum_1^k\\phi_{ki}\\rho_{j-i}$$\n",
    "We regard the ACFs are given, take regression parameters $\\phi_{ki}$ and wish to solve for $\\phi_{kk}$.  \n",
    "which all together forms the Yule-Walker equations. \n",
    "\n",
    "__Example__  \n",
    "For lag 1, $\\rho_1 = \\phi_{11},\\rho_0\\Rightarrow \\rho_1=\\phi_{11}$\n",
    "\n",
    "For lag 2,  \n",
    "$\\rho_1 = \\phi_{21} + \\phi_{22}\\rho_1$  \n",
    "$\\rho_2 = \\phi_{21}\\rho_1 + \\phi_{22}$    \n",
    "$\\Rightarrow \\phi_{22} = \\frac{\\rho_2 - \\rho_1^2}{1-\\rho_1^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal and invertible\n",
    "__Causal/stationary__ if $X_t$ can be expressed as an MA($\\infty$) process\n",
    "\n",
    "__Invertible__ if $X_t$ can be expressed as an AR($\\infty$) process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duality between AR amd MA processes\n",
    "A finite-order stationary AR(p) process corresponds to a MA($\\infty$) process, and a finite-order invertible MA(q) corresponds to an AR($\\infty$) process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example__ Given model $X_t - \\phi_1 X_{t-1} - \\phi_2 X_{t-2} = a_t = \\theta a_{t-1}$\n",
    "\n",
    "Assume the process is causal, then $X_t = \\sum_0^\\infty \\psi_i a_{t-i} = a_t\\sum_0^\\infty \\psi_i B^i = \\psi(B)a_t$ by causal process  \n",
    "$\\phi(B)X_t = \\theta(B) a_t \\Rightarrow X_t = \\frac{\\theta(B)a_t}{\\phi(B)}$ by ARMA model  \n",
    "$\\Rightarrow \\Theta(B)/\\Phi(B)=\\Psi(B)$  \n",
    "\n",
    "Replace back into the model\n",
    "$1+\\theta B = (\\sum_0^\\infty \\psi_iB^i)(1-\\phi_1B - \\phi_2B^2)$\n",
    "\n",
    "Consider $B$, $\\theta B = \\psi_1B -\\phi_1B\\Rightarrow \\psi_1 = \\phi_1 + \\theta$\n",
    "\n",
    "Consider $B^2$, $0 = -\\theta_2B^2-\\psi_1\\theta_1B +\\psi_2B^2\\Rightarrow \\psi_2 = \\phi_2 + \\phi_1(\\phi_1+ \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the process is invertible, then  \n",
    "$a_t = \\sum_0^\\infty \\pi_i X_{t-i} = X_t\\sum_0^\\infty \\pi_i B^i$,  \n",
    "similarly we get $\\Phi(B)=\\Theta(B)\\Pi(B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wold Decomposition\n",
    "Any zero-mean process $\\{X_t\\}$ wgucg us bit deterministic can be expressed as a sum of $X_t = U_t + V_t$ where $\\{U_t\\}$ denotes an MA($\\infty$) process and $\\{V_t\\}$ is a deterministic process which is uncorrelated with $\\{U_t\\}$\n",
    " - __deterministic__ if the values $X_{n+j}, j\\geq 1$ of the process $\\{X_t\\}$ were perfectly predicatable in term of $\\mu_n=sp\\{X_t\\}$\n",
    " - If $X_n$ comes from a deterministic process, it can be predicted (or determined) by its past observations of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model identification\n",
    "\n",
    "| process | ACF | PACF | \n",
    "| --- | --- | --- | \n",
    "|AR(p) | tails off | cuts off after lag p|\n",
    "|MA(q) | cuts off after lag q | tails off | \n",
    "|ARMA(p,q)| tails off after (q-p)| tails off after (p-q)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Adequacy\n",
    "The overall tests that check an entire group of residual autocorrelation functions are called portmanteau tests.\n",
    "\n",
    "__Box and Pierce__ $Q = n \\sum_1^m \\hat\\rho_k^2 \\sim \\chi^2_{m-(p+q)}$  \n",
    "__Ljung and Box__ $Q=\\sum_1^m \\frac{n(n+2)\\hat\\rho_k^2}{n-k}\\sim \\chi^2_{m-(p+q)}$  \n",
    "$n$ is the number of observations  \n",
    "$m$ is the max lag  \n",
    "$p,q$ are fitted model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection\n",
    "$AIC = -2\\log ML + 2k$  \n",
    "$BIC = -2 \\log ML + k \\log n $\n",
    "\n",
    "BIC puts more penalties on the number of parameters"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
