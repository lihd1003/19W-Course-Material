{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method of Conjugate Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Defn_. Q-Conjugate\n",
    "Let $Q$ be symmetric. We say that $d,d'$ are $Q$-conjugate or $Q$-orthogonal if $d^TQd' = 0$. A finite set $d_0, \\dots, d_k$ of vectors is called $Q$-orthogonal if $d_i^TQd_j = 0$ for all $i \\geq j$.\n",
    "\n",
    "For example, if $Q = I$, then $Q$-orthogonality is equivalent to regular orthogonality. For another example, if $Q$ has more than one distinct eigenvalue, let $d$ and $d'$ be eigenvectors corresponding to distinct eigenvalues. Then $d^TQd' = \\lambda' d^Td' = 0$, since the distinct eigenspaces of a symmetric matrix are orthogonal subspaces.\n",
    "\n",
    "Recall that any symmetric matrix $Q$ may the orthogonally diagonalized; there exists an orthonormal basis $d_0, \\dots, d_{n-1}$ of eigenvectors of $Q$. These eigenvectors are also $Q$-orthogonal. Hence to any symmetric matrix is a basis of orthonormal vectors that are also orthogonal with respect to the matrix, as just defined.\n",
    "\n",
    "### Examples of Q-conjugate set\n",
    "\n",
    "__Claim__. If $Q$ is symmetric and positive definite, then any set of non-zero $Q$-orthogonal vectors $\\{d_i\\}$ is linearly independent.\n",
    "\n",
    "_proof_. If $\\sum \\alpha_i d_i = 0$, then left-multiplying by $d_j^TQ$ gives $\\alpha_j d_j^T Q d_j = 0$. Positive definiteness implies $\\alpha_j = 0$. \n",
    "\n",
    "Let $Q$ be an $n \\times n$ symmetric positive definite matrix. Recall that $f(x) = \\frac{1}{2}x^TQx - b^Tx$ has the unique global minimizer $x_* = Q^{-1}b$. Let $d_0, \\dots, d_{n-1}$ be non-zero $Q$-orthogonal vectors. Then $d_0, \\dots, d_{n-1}$ form a basis of $\\mathbb R^n$. Thus there are scalars $\\alpha_0, \\dots, \\alpha_{n-1}$ such that $x_* = \\sum \\alpha_i d_i$. We would like a formula for the $\\alpha_i$'s.\n",
    "\n",
    "Multiplying both sides of the sum $x_* = \\sum \\alpha_i d_i$ by $d_j^TQ$ implies that $d_j^TQx_* = \\alpha_j d_j^TQd_j$, implying that\n",
    "$$\\alpha_j = \\frac{d_j^T b}{d_j^TQd_j}$$\n",
    "Therefore\n",
    "$$x_* = \\sum_{i=1}^{n-1} \\frac{d_i^Tb}{d_i^TQd_i}  d_i$$\n",
    "This implies that we can actually solve for $x_*$ by computing the $d_0, \\dots, d_{n-1}$ and the coefficients above. Computationally, computing inner products is very easy. The disadvantage is that we do not know how to find the vectors $d_0, \\dots, d_{n-1}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Thrm_. Conjugate Directions\n",
    "\n",
    "__Claim__. Let $d_0, \\dots, d_{n-1}$ be a set of non-zero $Q$-orthogonal vectors.  \n",
    "For a starting point $x_0 \\in \\mathbb R^n$, consider the sequence $\\{x_l\\}$ defined by \n",
    "$$x_{k+1} = x_k + \\alpha_k d_k$$\n",
    "where $$\\alpha_k = -\\frac{g_k^Td_k}{d_k^TQd_k}, g_k = Qx_k - b$$\n",
    "The sequence $\\{x_k\\}$ converges to the minimizer $x_*$ it at most $n$ steps; $x_n = x_*$.\n",
    "\n",
    "_proof_. Write $x_* - x_0 = \\alpha_0' d_0 + \\cdots + \\alpha_{n-1}'d_{n-1}$. Multiply both sides by $d_i^TQ$ to get\n",
    "$$\n",
    "d_i^TQ(x_* - x_0) = \\alpha_i d_i^TQd_i,\n",
    "$$\n",
    "giving us the expression\n",
    "$$\n",
    "\\tag{*}\n",
    "\\alpha_i' = \\frac{d_i^TQ(x_*-x_0)}{d_i^TQd_i}.\n",
    "$$\n",
    "Note that\n",
    "\\begin{align*}\n",
    "x_1 &= x_0 + \\alpha_0 d_0 \\\\\n",
    "x_2 &= x_0 + \\alpha_0 d_0 + \\alpha_1 d_1 \\\\\n",
    "&\\vdots \\\\\n",
    "x_k &= x_0 + \\alpha_0 d_0 + \\cdots + \\alpha_{k-1}d_{k-1},\n",
    "\\end{align*}\n",
    "implying that\n",
    "$$\n",
    "x_k - x_0 = \\alpha_0 d_0 + \\cdots + \\alpha_{k-1}d_{k-1}.\n",
    "$$\n",
    "Multiplying both sides by $d_k^TQ$ gives $d_k^TQ(x_k-x_0) = 0$. By (*) we have\n",
    "$$\n",
    "\\alpha_k' = \\frac{d_k^T Q(x_* - x_0) - d_k^TQ(x_k - x_0)}{d_k^TQd_k} = \\frac{d_k^TQ(x_* - x_k)}{d_k^TQd_k} = -\\frac{(Qx_k - Qx_*)^T d_k}{d_k^TQd_k}\n",
    "$$\n",
    "simplifying to\n",
    "$$\n",
    "\\alpha_k' = -\\frac{g_k^T d_k}{d_k^TQd_k} = \\alpha_k.\n",
    "$$\n",
    "So\n",
    "$$\n",
    "x_* = x_0 + \\alpha_0 d_0 + \\cdots + \\alpha_{n-1}d_{n-1} = x_n.\n",
    "$$\n",
    "So after $n$ steps, we reach the minimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Thrm_. Geometric Interpretation\n",
    "Let $d_0, \\dots, d_{n-1}$ be a set of non-zero $Q$-orthogonal vectors in $\\mathbb R^n$, where $Q$ is symmetric and positive definite. Note that these vectors are linearly independent by a result from last lecture. Let $B_k$ denote the subspace spanned by the first $k$ vectors. We have an increasing sequence\n",
    "$$B_0 \\subsetneq B_1 \\subsetneq \\cdots \\subsetneq B_n$$\n",
    "and $\\dim(B_k) = k$.\n",
    "\n",
    "__Lemma__. Let $f$ be a $C^1$ convex function defined on a convex domain $\\Omega \\subseteq \\mathbb R^n$. Suppose there is an $x_* \\in \\Omega$ such that $\\nabla f(x_*) \\cdot (y - x_*) \\geq 0$ for all $y \\in \\Omega$. Then $x_*$ is a global minimizer of $f$ on $\\Omega$. The converse is obviously true.\n",
    "\n",
    "_Geometrically, this means that if we move in any feasible direction from the point $x_*$, the function is increasing. Hence $x_*$ is a local minimizer; convexity implies it is global. With this result in mind, we prove the theorem._\n",
    "\n",
    "_proof_. The affine subspace $\\Omega = x_0 + B_k$ is convex. \\textbf{(This proof could not be finished as attention had to be diverted from the lecture.)}\n",
    "\n",
    "__Corollary__. $x_n$ minimizes $f(x)$ on $\\mathbb R^n$. That is, $x_n = x_*$; the method of conjugate directions for this function $f$ terminates in at most $n$ steps. \n",
    "\n",
    "__Claim__. The sequence $\\{x_k\\}_{k=0}^\\infty$ generated from $x_0$ by the method of conjugate directions has the property that $x_k$ minimizes $f(x) = \\frac{1}{2}x^TQx - b^Tx$ on the affine subspace $x_0 + B_k$.\n",
    "\n",
    "When $Q = I$, then $q(x)$ is half the distance squared from $x$ to $x_*$. What if $Q \\neq I$. $q$ is still a metric on $\\mathbb R^n$. Thus $x_k$ is the point \"closest\" to $x_*$ on the affine subspace $x_0 + B_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate Gradients\n",
    "\n",
    "Start at $x_0 \\in \\mathbb R^n$. Choose $d_0 = -g_0 = -\\nabla f(x_0) = b - Qx_0$. Recursively define $d_{k+1} = -g_{k+1} + \\beta_k d_k$, where $g_{k+1} = Qx_{k+1} - b$ and\n",
    "$$\n",
    "\\beta_k = \\frac{g_{k+1}^T Q d_k}{d_k^TQd_k}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "x_{k+1} = x_k + \\alpha_k d_k,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\alpha_k = -\\frac{g_k^T d_k}{d_k^T Q d_k}.\n",
    "$$\n",
    "\n",
    "Given an initial point $x_0$, take $d_0 = -g_0 = b - Qx_0$. By definition, $x_1 = x_0 + \\alpha_0 d_0$; we need to find $\\alpha_0$. This is\n",
    "$$\n",
    "\\alpha_0 = -\\frac{g_0^Td_0}{g_0^TQg_0}.\n",
    "$$\n",
    "Then $x_2 = x_1 + \\alpha_1 d_1$. By definition, $\\alpha_1 = -\\frac{g_1^T d_1}{d_1^TQd_1}$, where $d_1 = -g_1 + \\beta_0 d_0$, where $\\beta_0 = \\frac{g_1^TQd_0}{d_0^TQd_0}$.\n",
    "\n",
    "Some remarks:\n",
    "- Like the other conjugate direction methods, this method converges to the minimizer $x_*$ in $n$ steps.\n",
    "- We have a procedure to find the direction vectors $d_k$.\n",
    "- This method makes good uniform progress towards the solution at every step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Thrm_. Bound on Convergence\n",
    "__Claim__. consider $q(x) = \\frac{1}{2}(x-x_*)^TQ(x-x_*) = f(x) + \\text{const}$. It's better to look at $q$ rather than $f$, since $q$ behaves like a distance function relative to $x_*$.\n",
    "$$q(x_{k+1}) \\leq \\left( \\max_{\\substack{\\lambda \\\\ \\text{eigval of Q}}} (1 + \\lambda P_k(\\lambda))^2 \\right) q(x_k)$$\n",
    "where $P_k$ is any polynomial of degree $k$.\n",
    "\n",
    "For example, suppose $Q$ has $m \\leq n$ distinct eigenvalues. Choose a polynomial $P_{m-1}$ such that $1 + \\lambda P_{m-1}(\\lambda)$ has its $m$ zeroes at the $m$ eigenvalues of $Q$. With such a polynomial, we would get $q(x_m) \\leq 0$, implying that $q(x_m) = 0$; the conjugate gradient method terminates at the $m$th step, i.e. $x_m=x_*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "_Let $c\\in\\mathbb R^n - \\{0\\}, f(x) = \\frac12x^TQx-b^Tx, Q = I +cc^T$. Using conjugate gradient method, what's the smallest $k$ that guarantees $x_k$ is the minimizer of $f$_\n",
    "\n",
    "__Claim__. $k=2$\n",
    "\n",
    "_proof_. First, consider some eigenvalues $\\lambda$ and corresponding eigenvector $x$, by definition, we have \n",
    "\\begin{align*}\n",
    "\\lambda x &= Qx\\\\\n",
    "\\lambda x &= (I + cc^T)x\\\\\n",
    "\\lambda x &= x + cc^Tx\\\\\n",
    "(\\lambda - 1)x &= (c^Tx)c &\\text{Note that }c^Tx\\in\\mathbb R\n",
    "\\end{align*}\n",
    "If $\\lambda - 1 = 0$, we must have $c^Tx = 0$, so that $\\lambda = 1$ is a eigenvalue,  \n",
    "If $\\lambda - 1 \\neq 0$, then $x$ and $c$ are linearly dependent, hence the eigenvector is $c$ and we have \n",
    "\\begin{align*}\n",
    "\\lambda c &= (I + cc^T)c\\\\\n",
    "\\lambda c &= c + cc^Tc\\\\\n",
    "\\lambda &= 1 + c^Tc\n",
    "\\end{align*}\n",
    "Therefore, there are only 2 distinct eigenvalues for $Q = I + cc^T$.  \n",
    "\n",
    "Then, we can take $P_1(\\lambda) = a + b\\lambda$ be a polynomial of degree 1 s.t. \n",
    "$$\\begin{bmatrix}\n",
    "1&1\\\\\n",
    "1&1+c^Tc\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "a\\\\b\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "-1\\\\-\\frac{1}{1+c^Tc}\n",
    "\\end{bmatrix}$$\n",
    "so that $1+P(1) = 0$ and $1+(1+cc^T)P(1+cc^T) =0$. \n",
    "Therefore, we have \n",
    "$$q(x_2) \\leq \\max_{\\lambda \\in \\{1, 1+c^Tc\\}}(1+\\lambda P_1(\\lambda))q(x_0) = 0$$\n",
    "Therefore, $k = 2$ guarantees $x_2$ is the minimizer of $f$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "_Let $Q = \\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}, b = \\begin{bmatrix}25&8\\end{bmatrix}, f = \\frac{1}{2}x^TQx - b^Tx$_\n",
    "\n",
    "_(a) Find eigenvalues $\\lambda_0\\leq \\lambda_1$ of $Q$ and corresponding eigenvectors_. \n",
    "\n",
    "First, find its characteristic polynomial as \n",
    "$$(2-\\lambda)^2 - 25 = \\lambda^2 - 4\\lambda + 4 -25 = \\lambda^2 - 4\\lambda+21=(\\lambda-7)(\\lambda+3)$$\n",
    "set the equation to $0$ and solve to get\n",
    "$$\\lambda_0 = -3, \\lambda_1 = 7$$\n",
    "Then, \n",
    "\\begin{align*}\n",
    "(Q - \\lambda_0I)d_0 &= 0\\\\\n",
    "\\begin{bmatrix}5&-5\\\\-5&5\\end{bmatrix}d_0 &= 0\\\\\n",
    "d_0&= \\begin{bmatrix}1\\\\1\\end{bmatrix}\\\\\n",
    "(Q - \\lambda_1I)d_1 &= 0\\\\\n",
    "\\begin{bmatrix}-5&-5\\\\-5&-5\\end{bmatrix}d_1 &= 0\\\\\n",
    "d_1&= \\begin{bmatrix}1\\\\-1\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "_(b) Compute the steps of conjugate directions method given directions $d_0, d_1$_\n",
    "\n",
    "\\begin{align*}\n",
    "g_0 &= \\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}25\\\\5\\end{bmatrix} - \\begin{bmatrix}25\\\\8\\end{bmatrix}= \\begin{bmatrix}0\\\\-123\\end{bmatrix}\\\\\n",
    "a_0 &= -(\\begin{bmatrix}0\\\\-123\\end{bmatrix}^T\\begin{bmatrix}1\\\\1\\end{bmatrix}) / (\\begin{bmatrix}1\\\\1\\end{bmatrix}^T\n",
    "\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}1\\\\1\\end{bmatrix})= -\\frac{41}2\\\\\n",
    "x_1 &= \\begin{bmatrix}25\\\\5\\end{bmatrix}-\\frac{41}2\\begin{bmatrix}1\\\\1\\end{bmatrix}= \\begin{bmatrix}4.5\\\\-15.5\\end{bmatrix}\\\\\n",
    "g_1 &= \n",
    "\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\n",
    "\\begin{bmatrix}4.5\\\\-15.5\\end{bmatrix} - \n",
    "\\begin{bmatrix}25\\\\8\\end{bmatrix}= \\begin{bmatrix}61.5\\\\-61.5\\end{bmatrix}\\\\\n",
    "a_1 &= -(\\begin{bmatrix}61.5\\\\-61.5\\end{bmatrix}^T\\begin{bmatrix}1\\\\-1\\end{bmatrix}) / (\\begin{bmatrix}1\\\\-1\\end{bmatrix}^T\n",
    "\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}1\\\\-1\\end{bmatrix})= -\\frac{123}{14}\\\\\n",
    "x_2 &= \\begin{bmatrix}-4.5\\\\15.5\\end{bmatrix}-\\frac{123}{14}\\begin{bmatrix}1\\\\-1\\end{bmatrix}= \\begin{bmatrix}-\\frac{30}7\\\\-\\frac{47}7\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "_(c) Compute the steps of conjugate directions method given directions $d_1, d_0$_\n",
    "\n",
    "\\begin{align*}\n",
    "g_0 &= \\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}25\\\\5\\end{bmatrix} - \\begin{bmatrix}25\\\\8\\end{bmatrix}= \\begin{bmatrix}0\\\\-123\\end{bmatrix}\\\\\n",
    "a_0 &= -(\\begin{bmatrix}0\\\\-123\\end{bmatrix}^T\\begin{bmatrix}1\\\\-1\\end{bmatrix}) / (\\begin{bmatrix}1\\\\-1\\end{bmatrix}^T\n",
    "\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}1\\\\-1\\end{bmatrix})= -\\frac{123}{14}\\\\\n",
    "x_1 &= \\begin{bmatrix}25\\\\5\\end{bmatrix}-\\frac{123}{14}\\begin{bmatrix}1\\\\-1\\end{bmatrix}= \\begin{bmatrix}\\frac{227}{14}\\\\\\frac{193}{14}\\end{bmatrix}\\\\\n",
    "g_1 &= \n",
    "\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\n",
    "\\begin{bmatrix}\\frac{227}{14}\\\\\\frac{193}{14}\\end{bmatrix} - \n",
    "\\begin{bmatrix}25\\\\8\\end{bmatrix}= \\begin{bmatrix}61.5\\\\-61.5\\end{bmatrix}\\\\\n",
    "a_1 &= -(\\begin{bmatrix}61.5\\\\-61.5\\end{bmatrix}^T\\begin{bmatrix}1\\\\1\\end{bmatrix}) / (\\begin{bmatrix}1\\\\1\\end{bmatrix}^T\n",
    "\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}1\\\\1\\end{bmatrix})= -\\frac{41}{2}\\\\\n",
    "x_2 &= \\begin{bmatrix}\\frac{227}{14}\\\\\\frac{193}{14}\\end{bmatrix}-\\frac{41}{2}\\begin{bmatrix}1\\\\1\\end{bmatrix}= \\begin{bmatrix}-\\frac{30}7\\\\-\\frac{47}7\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "_(d) Compute the steps of conjugate gradients_\n",
    "\n",
    "\\begin{align*}\n",
    "g_0 &= \\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}25\\\\5\\end{bmatrix} - \\begin{bmatrix}25\\\\8\\end{bmatrix}= \\begin{bmatrix}0\\\\-123\\end{bmatrix}\\\\\n",
    "d_0 &= \\begin{bmatrix}0\\\\123\\end{bmatrix}\\\\\n",
    "a_0 &= (\\begin{bmatrix}0\\\\123\\end{bmatrix}\\cdot\\begin{bmatrix}0\\\\123\\end{bmatrix}) / \n",
    "\\begin{bmatrix}0\\\\123\\end{bmatrix}\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}0\\\\123\\end{bmatrix} = 0.5\\\\\n",
    "x_1 &= \\begin{bmatrix}25\\\\5\\end{bmatrix} + 0.5\\begin{bmatrix}0\\\\123\\end{bmatrix}= \\begin{bmatrix}25\\\\66.5\\end{bmatrix}\\\\\n",
    "g_1 &=\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}25\\\\66.5\\end{bmatrix} - \\begin{bmatrix}25\\\\8\\end{bmatrix}= \\begin{bmatrix}-307.5\\\\0\\end{bmatrix}\\\\\n",
    "\\beta_0 &= (\\begin{bmatrix}-307.5\\\\0\\end{bmatrix}^T\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}0\\\\123\\end{bmatrix}) / (\\begin{bmatrix}0\\\\123\\end{bmatrix}^T\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}0\\\\123\\end{bmatrix})=6.25\\\\\n",
    "d_1 &= \\begin{bmatrix}307.5\\\\0\\end{bmatrix} + 6.25\\begin{bmatrix}0\\\\123\\end{bmatrix} = \\begin{bmatrix}307.5\\\\768.75\\end{bmatrix}\\\\\n",
    "a_1 &= (\\begin{bmatrix}-307.5\\\\0\\end{bmatrix}\\cdot\\begin{bmatrix}307.5\\\\768.75\\end{bmatrix}) / \n",
    "\\begin{bmatrix}307.5\\\\768.75\\end{bmatrix}\\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}307.5\\\\768.75\\end{bmatrix} = -\\frac{2}{21}\\\\\n",
    "x_2 &= \\begin{bmatrix}25\\\\66.5\\end{bmatrix} + \\frac{2}{21}\\begin{bmatrix}307.5\\\\768.75\\end{bmatrix} = \\begin{bmatrix}-\\frac{30}7\\\\-\\frac{47}7\\end{bmatrix}\\\\\n",
    "g_2 &= \\begin{bmatrix}2&-5\\\\-5&2\\end{bmatrix}\\begin{bmatrix}-\\frac{30}7\\\\-\\frac{47}7\\end{bmatrix} - \\begin{bmatrix}25\\\\8\\end{bmatrix} = \\begin{bmatrix}0\\\\0\\end{bmatrix}\\\\\n",
    "\\beta_1 &= \\frac{0}{d_1^TQd_1} = 0\\\\\n",
    "d_2 &= -g_2 + 0 = \\begin{bmatrix}0\\\\0\\end{bmatrix}\\\\\n",
    "x_3 &= x_2 + a_2\\begin{bmatrix}0\\\\0\\end{bmatrix} = x_2 = \\begin{bmatrix}-\\frac{30}7\\\\-\\frac{47}7\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3\n",
    "_Prove that the Gram-Schmidt procedure generate a sequence of Q-conjugate directions given a linear independent set of vector $p_0,...,p_{n-1}\\in\\mathbb R^n$_\n",
    "\n",
    "_proof_. Note that this statement is equal to say that $\\forall k\\in\\{0,...,n-1\\}. \\forall j < k. d_k^TQd_j = 0$, and I'll prove this statement by strong induction.\n",
    "\n",
    "First, since $Q$ is symmetric $d_k^TQd_j = d_j^TQd_k$ for any $d_j,d_k$.  Also note that since $d_k$'s are linear combinations of $p_0, ..., p_{n-1}$, $d_k\\neq 0, \\forall k\\in\\{0,...,n-1\\}$, and since $Q$ is positive definite $d_K^TQd_k > 0$. \n",
    "\n",
    "Then, note that for $k = 0$, the statement is vacuously true.   \n",
    "Fir $k \\in \\{1, ..., n-1\\}$, assume that $\\forall m < k. \\forall j < m. d_m^TQd_j = d_j^TQd_m = 0$, i.e. $\\forall j,m < k, j\\neq m. d^T_mQd_j = 0$ Then, for some $i < k$, we have\n",
    "\\begin{align*}\n",
    "d_{k}^TQd_{j} &= (p_k - \\sum_{i=0}^{k-1}\\frac{p_k^TQ d_i}{d_i^TQd_i}d_i)^TQd_j\\\\\n",
    "&= p_k^TQd_j- \\sum_{i=0}^{k-1}\\frac{p_k^TQ d_i}{d_i^TQd_i}d_i^TQd_j\\\\\n",
    "&= p_k^TQd_j - \\frac{p_k^TQ d_i}{d_j^TQd_j}d_j^TQd_j\\\\\n",
    "&= p_k^TQd_j - p_k^TQd_j\\\\\n",
    "&= 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4\n",
    "_Let $Q$ be positive definite, $f(x) = \\frac12 x^TQx - b^Tx$. Let $x_1=\\arg\\min_{x\\in S_1}f(x), x_2=\\arg\\min_{x\\in S_2}f(x)$, where $S_1,S_2\\subset E^n$ and $d\\in S_1\\cap S_2$, assume $f(x_1) < f(x_2)$. Show that $(x_1-x_2)^TQd = 0$._\n",
    "\n",
    "_proof_. Since $x_1$ is a minimizer of $S_1$, we must have $\\nabla f(x_1)^T = 0$, otherwise we can have some $\\epsilon > 0, f(x_1 - \\epsilon d) < f(x_1)$ and $x_1-\\epsilon d \\in S_1$ since $x_1\\in S_1, d\\in S_1$. Note that the equation is expanded as\n",
    "\\begin{align*}\n",
    "\\nabla f(x_1)^T d &= (Qx_1 - b)^Td \\\\\n",
    "&= x_1^TQ^Td - b^Td \\\\\n",
    "&= x_1^TQd - b^Td &Q\\text{ is symmetric}\\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "\n",
    "and similarly we have $\\nabla f(x_2)^T d = x_2^TQd - b^Td= 0$.    \n",
    "\n",
    "Therefore, we have \n",
    "\\begin{align*}\n",
    "(x_1-x_2)^TQd &= x_1^TQd - x_2^TQd \\\\\n",
    "&= b^Td - b^Td \\\\\n",
    "&= 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5\n",
    "_Let $f = \\frac12x^TQx - b^Tx$ where $Q = diag(\\lambda_1,...,\\lambda_n)$ being a diagonal, positive definite and symmetric matrix._\n",
    "\n",
    "_(a) Show that standard basis vectors form a Q-orthogonal set_\n",
    "\n",
    "_proof._ Let $i, j \\in\\{1, ...,n\\}, i\\neq j$.  \n",
    "Denote $e_{mk}$ be the $k$th entry of $e_m$, $Q_{ij}$ be the entry on $i$th row and $j$th column of $Q$\n",
    "$$e_i^TQe_j = \\sum_{p=1}^n\\sum_{q=1}^nQ_{pq}e_{ip}e_{jq}$$\n",
    "Note that  \n",
    "$Q_{pp} = \\lambda_i, Q_{pq}=0$, for any $p,q\\in\\{1,...,n\\}, p\\neq q$.  \n",
    "$e_{ii}=1, e_{ip}=0$ for $p\\in\\{1,...,n\\}-\\{i\\}$  \n",
    "$e_{jj}=1, e_{jq}=0$ for $q\\in\\{1,...,n\\}-\\{j\\}$  \n",
    "Therefore, consider each term of the summation, when $p\\neq q, Q_{pq}=0$, when $p=q$, at least one of $e_{ip},e_{jq}$ equals 0. Therefore, all terms in the summation are 0, $e_i^TQe_j = 0$, hence $\\{d_0,...,d_{n-1}\\} = \\{e_1,...,e_n\\}$ forms a Q-orthogonal set. \n",
    "\n",
    "_(b) Prove $x_k = (\\frac{b_1}{\\lambda_1},...,\\frac{b_k}{\\lambda_k}, a_{k+1},...,a_n)$ is the $k$th step of Conjugate direction method, starting from $x_0 = (a_1,...,a_n)$_\n",
    "\n",
    "_proof_. I'll prove by induction.  \n",
    "Let $k\\in \\{1,...,n-2\\}$, assume $x_{k} = (\\frac{b_1}{\\lambda_1},...,\\frac{b_k}{\\lambda_k}, a_{k+1},...,a_n)$. Consider the $(k+1)$th step of conjugate direction method.  \n",
    "$$g_k = Qx_k - b = \n",
    "\\begin{bmatrix}\n",
    "\\lambda_1\\frac{b_1}{\\lambda_1} - b_1\\\\\n",
    "\\cdots\\\\\n",
    "\\lambda_k\\frac{b_k}{\\lambda_k} - b_k\\\\\n",
    "\\lambda_{k+1}a_{k+1} - b_{k+1}\\\\\n",
    "\\cdots\\\\\n",
    "\\lambda_{n}a_n - b_{n}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "0\\\\\n",
    "\\cdots\\\\\n",
    "0\\\\\n",
    "\\lambda_{k+1}a_{k+1} - b_{k+1}\\\\\n",
    "\\cdots\\\\\n",
    "\\lambda_{n}a_n - b_{n}\n",
    "\\end{bmatrix}$$\n",
    "$$a_k = -\\frac{g_k^Td_k}{d_k^TQd_k}=-\\frac{g_k^Te_{k+1}}{e_{k+1}^TQe_{k+1}}-\\frac{\\lambda_{k+1}a_{k+1} - b_{k+1}}{\\lambda_{k+1}} = -a_{k+1}+\\frac{b_{k+1}}{\\lambda_{k+1}}$$\n",
    "$$x_{k+1} = x_k + a_kd_k = x_k + a_ke_{k+1} \n",
    "\\begin{bmatrix}\n",
    "\\frac{b_1}{\\lambda_1}\\\\\n",
    "\\cdots\\\\\n",
    "\\frac{b_k}{\\lambda_k}\\\\\n",
    "a_{k+1} -a_{k+1}+\\frac{b_{k+1}}{\\lambda_{k+1}}\\\\\n",
    "a_{k+2}\\\\\n",
    "\\cdots\\\\\n",
    "a_n\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{b_1}{\\lambda_1}\\\\\n",
    "\\cdots\\\\\n",
    "\\frac{b_{k+1}}{\\lambda_{k+1}}\\\\a_{k+2}\\\\\n",
    "\\cdots\\\\\n",
    "a_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "_(c) Prove that $\\forall k \\geq 1, x_k$ is the minimizer of $f$ in the set $x_0 + \\mathcal B_k, \\mathcal B_k = span\\{d_0,...,d_{k-1}\\} = span\\{e_1,...,e_k\\}$_\n",
    "\n",
    "_proof_. Let \n",
    "\\begin{align*}\n",
    "\\phi(y_1,...,y_k)&=f(x_0 + \\sum_{i=1}^k{y_ie_i})\\\\\n",
    "&=(x_0 + \\sum_{i=1}^k{y_ie_i})^TQ(x_0 + \\sum_{i=1}^k{y_ie_i})-b^T(x_0 + \\sum_{i=1}^k{y_ie_i})\n",
    "\\end{align*}\n",
    "Therefore, the problem is equivalent to minimize $\\phi$ on $\\in\\mathbb R^k$.  \n",
    "Note that \n",
    "$$\\frac{\\partial\\phi}{\\partial y_i} = Q_{i\\cdot}(x_{0i}+y_i) - b_i = \\lambda_i(a_i+y_i) - b_i$$\n",
    "for $i=1,2,..,k$,  \n",
    "Therefore, set the derivative to $0$ to satisfy the FONC, we have $k$ equations \n",
    "$$\\lambda_i(a_i+y_i)-b_i=0\\Rightarrow y_i =\\frac{b_i}{\\lambda_i}-a_i$$\n",
    "Then, note that $\\frac{\\partial^{2}\\phi}{\\partial y_i^2} = \\lambda_i, \\frac{\\partial^{2}\\phi}{\\partial y_i y_j} = 0$ for $i,j\\in\\{1,...,k\\}, i\\neq j$, we have $\\nabla^2\\phi = diag(\\lambda_1,...,\\lambda_k)$, i.e. the top-left $k\\times k$ submatrix of $Q$, since $Q$ is positive definite, $\\nabla^2\\phi$ is also positive definite, SOC also holds and \n",
    "$$x_0 + \\sum_{i-1}^k(\\lambda_i(a_i+y_i)-b_i)e_i = (\\frac{b_1}{\\lambda_1},...,\\frac{b_k}{\\lambda_k}, a_{k+1}, ..., a_n) = x_k$$\n",
    "is the minimizer of $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6\n",
    "_Let $Q$ be a positive definite symmetric matrix._\n",
    "\n",
    "_(a) Prove $d(x, y) = [(x-y)^TQ(x-y)]^{1/2}$ is a metric._ \n",
    "\n",
    "_proof_. Let $x,y\\in\\mathbb R^n$.  \n",
    "\n",
    "__positive definite__  \n",
    "Since $Q$ is positive definite, \n",
    "$$\\forall a\\in\\mathbb R^n. a^TQa \\geq 0\\land a^TQa = 0\\Leftrightarrow a = 0$$ Hence\n",
    "$$(x-y)^TQ(x-y) \\geq 0\\land (x-y)^TQ(x-y) = 0\\Leftrightarrow x-y = 0\\Leftrightarrow x=y$$\n",
    "Therefore, \n",
    "$$d(x,y)=[(x-y)^TQ(x-y)]^{1/2} \\geq 0\\land [(x-y)^TQ(x-y)]^{1/2} = 0\\Leftrightarrow x=y$$\n",
    "\n",
    "__symmetric__  \n",
    "\\begin{align*}\n",
    "d(x,y) &= [(x-y)^TQ(x-y)]^{1/2} \\\\\n",
    "&= [(-(y-x))^TQ(-(y-x))]^{1/2}\\\\\n",
    "&= [-1(-1)(y-x)^TQ(y-x)]^{1/2}\\\\\n",
    "&= [(y-x)^TQ(y-x)]^{1/2}\\\\\n",
    "&= d(y,x)\n",
    "\\end{align*}\n",
    "\n",
    "__triangular inequality__  \n",
    "\\begin{align*}\n",
    "d(x,z)&= [(x-z)^TQ(x-z)]^{1/2}\\\\\n",
    "&= [((x-y)+(y-z))^TQ((x-y)+(y-z))]^{1/2}\\\\\n",
    "&= [(x-y)^TQ(x-y) + (y-z)^TQ(y-z)]^{1/2}\\\\\n",
    "&= (d(x,y)^{2} + d(y,z)^2)^{1/2}\\\\\n",
    "&\\text{by triangular inequality on Euclidean norm of real numbers}\\\\\n",
    "&\\leq (d(x,y)^{2})^{1/2} + (d(x,y)^{2})^{1/2} \\\\\n",
    "&= d(x,y) + d(y,z)\n",
    "\\end{align*}\n",
    "\n",
    "_(b) For $x^*\\in\\mathbb R^2, a\\in\\mathbb R$, for $x$ on the line $L = \\{x\\in\\mathbb R^2\\mid x=(t,at), t\\in\\mathbb R\\}$, find $x$ that minimizes $d(x,x^*)$._\n",
    "\n",
    "Define \n",
    "$$f(x, y) = d((x, y), (x^*, y^*)) = \\frac12 \\begin{bmatrix}x-x^*\\\\y-y^*\\end{bmatrix}^TQ\\begin{bmatrix}x-x^*\\\\y-y^*\\end{bmatrix}$$\n",
    "therefore minimizing $d((x,y), (x^*, y^*))$ on $L$ is equivalent to \n",
    "\\begin{align*}&\\text{minimize } &f(x,y)\\\\\n",
    "&\\text{subject to} &l(x,y) = ax-y = 0\n",
    "\\end{align*}\n",
    "Note that $\\nabla f = Q\\begin{bmatrix}x-x^*\\\\y-y^*\\end{bmatrix}, \\nabla l = \\begin{bmatrix}a\\\\-1\\end{bmatrix}$\n",
    "using Lagrange multiplier, we have equations \n",
    "\\begin{align*}\n",
    "Q\\begin{bmatrix}t-x^*\\\\at-y^*\\end{bmatrix} + \\lambda\\begin{bmatrix}a\\\\-1\\end{bmatrix}= 0 \n",
    "\\end{align*}\n",
    "Therefore, since $Q$ is symmetric, write $Q = \\begin{bmatrix}p&m\\\\m&q\\end{bmatrix}$we can solve for \n",
    "$$t = \\frac{(p+m)x^* + (q+m)x^*}{a^2q + 2am + p}$$\n",
    "Since $Q$ is positive definite, this solution is the minimum. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
